{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import fetch_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli = fetch_datasets()['abalone']\n",
    "X, y = ecoli.data, ecoli.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# data = load_breast_cancer()\n",
    "# X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "default_classes = np.unique(y)\n",
    "print(default_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3786 instances for the majoritary class\n",
      "There are 391 instanes for the minoritary class\n"
     ]
    }
   ],
   "source": [
    "maj_class = -1\n",
    "min_class = 1\n",
    "if sum(y == default_classes[0]) > sum(y == default_classes[1]):\n",
    "#     maj_class = default_classes[0]\n",
    "#     min_class = default_classes[1]\n",
    "    y[y==default_classes[0]] = maj_class\n",
    "    y[y==default_classes[1]] = min_class\n",
    "else:\n",
    "#     maj_class = default_classes[1]\n",
    "#     min_class = default_classes[0]\n",
    "    y[y==default_classes[1]] = maj_class\n",
    "    y[y==default_classes[0]] = min_class\n",
    "    \n",
    "print(\"There are {} instances for the majoritary class\".format(sum(y == maj_class)))\n",
    "print(\"There are {} instanes for the minoritary class\".format(sum(y == min_class)))\n",
    "classes = [maj_class,min_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2839 instances for the majoritary class\n",
      "There are 293 instanes for the minoritary class\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=0)\n",
    "#number of features of the dataset \n",
    "D = X_train.shape[1]\n",
    "\n",
    "print(\"There are {} instances for the majoritary class\".format(sum(y_train == maj_class)))\n",
    "print(\"There are {} instanes for the minoritary class\".format(sum(y_train == min_class)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE-guided UNDERSAMPLING of the majority class instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import array\n",
    "\n",
    "from deap import base\n",
    "from deap import benchmarks\n",
    "from deap import creator\n",
    "from deap import tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate the initial random population from the training set\n",
    "def load_individuals(X,y,creator,n):\n",
    "    maj_samples = X[y == maj_class]\n",
    "    min_samples = X[y == min_class]\n",
    "    individuals = []\n",
    "    for i in range(n):\n",
    "        random_maj = maj_samples[random.randint(0,maj_samples.shape[0]-1)]\n",
    "        random_min = min_samples[random.randint(0,min_samples.shape[0]-1)]\n",
    "        individual = np.asarray(np.concatenate((random_maj,random_min)))\n",
    "        \n",
    "        individual = creator(individual)\n",
    "        individuals.append(individual)\n",
    "    return individuals\n",
    "\n",
    "# returns the euclidean distance between two points\n",
    "def euclidean(v1, v2):\n",
    "    return sum((p-q)**2 for p, q in zip(v1, v2)) ** .5\n",
    "\n",
    "#returns the sum of the distances from each sample in X_train to the closest center\n",
    "#we are interested in minimizing this sum of distances\n",
    "def evaluate(X,individual):\n",
    "    S = 0\n",
    "    for x in X:\n",
    "        dist = dist_to_closest_center(x,individual[:D],individual[D:])\n",
    "        S += dist\n",
    "        \n",
    "    return S,\n",
    "\n",
    "#computes the euclidean distance for both centers and returns the shortest one\n",
    "def dist_to_closest_center(x,maj_center,min_center):\n",
    "    dist_majcenter = euclidean(x,maj_center)\n",
    "    dist_mincenter = euclidean(x,min_center)\n",
    "    return min(dist_majcenter,dist_mincenter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristina/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/cristina/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "NDIM = D*2\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "#creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMin)\n",
    "#creator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "#toolbox.register(\"attr_float\", random.uniform, -3, 3)\n",
    "#toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, NDIM)\n",
    "#toolbox.register(\"individual\", selectRandomSamplesOneForEachClass, creator.Individual)\n",
    "toolbox.register(\"population\",load_individuals, X_train, y_train, creator.Individual)\n",
    "#toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"select\", tools.selRandom, k=3)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DE_clustering(CR,F,POP_SIZE,NGEN):\n",
    "    # Differential evolution parameters\n",
    "    #CR = 0.25\n",
    "    #F = 1  \n",
    "    #MU = 300\n",
    "    #NGEN = 200    \n",
    "    \n",
    "    pop = toolbox.population(n=POP_SIZE);\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
    "    \n",
    "    # Evaluate the individuals\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, pop)\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, evals=len(pop), **record)\n",
    "    print(logbook.stream)\n",
    "    \n",
    "    for g in range(1, NGEN):\n",
    "        for k, agent in enumerate(pop):\n",
    "            a,b,c = toolbox.select(pop)\n",
    "            y = toolbox.clone(agent)\n",
    "            index = random.randrange(NDIM)\n",
    "            for i, value in enumerate(agent):\n",
    "                if i == index or random.random() < CR:\n",
    "                    y[i] = a[i] + F*(b[i]-c[i])\n",
    "            y.fitness.values = toolbox.evaluate(y)\n",
    "            if y.fitness > agent.fitness:\n",
    "                pop[k] = y\n",
    "            #print(pop[k].fitness)\n",
    "        hof.update(pop)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=g, evals=len(pop), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "    print(\"Best individual is \", hof[0], hof[0].fitness.values[0])\n",
    "    return hof[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute H clustering processes and obtain one pair of cluster centers for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tevals\tstd    \tmin    \tavg    \tmax    \n",
      "0  \t10   \t487.217\t2322.35\t2871.19\t3721.12\n",
      "1  \t10   \t389.46 \t2322.35\t2786.17\t3539.06\n",
      "2  \t10   \t360.201\t2322.35\t2761.56\t3539.06\n",
      "3  \t10   \t325.04 \t2322.35\t2744.36\t3366.97\n",
      "4  \t10   \t325.04 \t2322.35\t2744.36\t3366.97\n",
      "5  \t10   \t320.38 \t2322.35\t2670.62\t3366.97\n",
      "6  \t10   \t324.397\t2319.88\t2666.69\t3366.97\n",
      "7  \t10   \t326.33 \t2319.88\t2649.22\t3366.97\n",
      "8  \t10   \t326.33 \t2319.88\t2649.22\t3366.97\n",
      "9  \t10   \t300.871\t2319.88\t2637.19\t3246.66\n",
      "Best individual is  Individual('d', [0.0, 0.0, 1.0, 0.6, 0.48, 0.17, 1.0575, 0.582, 0.2365, 0.33849999999999997, 0.0, 1.0, 0.0, 0.4, 0.29874999999999996, 0.105, 0.3415, 0.176, 0.13099999999999998, 0.15175]) 2319.8783515474347\n",
      "gen\tevals\tstd    \tmin    \tavg    \tmax    \n",
      "0  \t10   \t499.713\t2279.32\t2759.47\t3866.05\n",
      "1  \t10   \t482.712\t2279.32\t2740.99\t3783.74\n",
      "2  \t10   \t292.441\t2279.32\t2609.25\t3271.21\n",
      "3  \t10   \t292.623\t2187.41\t2485.98\t3271.21\n",
      "4  \t10   \t110.704\t2187.41\t2371.02\t2637.72\n",
      "5  \t10   \t89.7953\t2187.41\t2350.84\t2548.86\n",
      "6  \t10   \t88.8756\t2187.41\t2339.32\t2548.86\n",
      "7  \t10   \t58.7141\t2187.41\t2320.99\t2397.75\n",
      "8  \t10   \t52.0163\t2187.41\t2301.73\t2380.3 \n",
      "9  \t10   \t69.9181\t2160.38\t2278.86\t2380.3 \n",
      "Best individual is  Individual('d', [0.25, 0.0, 0.65625, 0.615, 0.515, 0.1303125, 1.0423437500000001, 0.4270625, 0.1546875, 0.2816328125, 0.0, 1.0, 0.0, 0.43734375000000003, 0.33953124999999995, 0.11125, 0.38584375, 0.16108593750000003, 0.082375, 0.1110078125]) 2160.380251969324\n",
      "gen\tevals\tstd    \tmin    \tavg   \tmax    \n",
      "0  \t10   \t453.649\t2348.57\t2850.3\t3686.43\n",
      "1  \t10   \t446.792\t2348.57\t2758.58\t3686.43\n",
      "2  \t10   \t446.792\t2348.57\t2758.58\t3686.43\n",
      "3  \t10   \t460.299\t2348.57\t2716.03\t3686.43\n",
      "4  \t10   \t466.899\t2272.41\t2708.42\t3686.43\n",
      "5  \t10   \t360.391\t2272.41\t2644.68\t3551.81\n",
      "6  \t10   \t278.374\t2272.41\t2599.8 \t3311.11\n",
      "7  \t10   \t277.383\t2272.41\t2547.38\t3311.11\n",
      "8  \t10   \t247.204\t2272.41\t2535.23\t3199.11\n",
      "9  \t10   \t128.804\t2238.66\t2419.74\t2615.1 \n",
      "Best individual is  Individual('d', [0.4375, 0.125, 0.71875, 0.61328125, 0.40093749999999995, 0.18, 1.02475, 0.43581250000000005, 0.2459609375, 0.43, 0.0, 1.0, 0.0, 0.46, 0.368125, 0.12875, 0.5445, 0.17959375, 0.1325, 0.15271875000000001]) 2238.662547648842\n",
      "gen\tevals\tstd    \tmin    \tavg    \tmax    \n",
      "0  \t10   \t291.979\t2453.09\t2645.12\t3490.22\n",
      "1  \t10   \t241.241\t2453.09\t2627.45\t3313.53\n",
      "2  \t10   \t90.4237\t2451.58\t2566.49\t2759.96\n",
      "3  \t10   \t51.4481\t2410.78\t2513.12\t2585.84\n",
      "4  \t10   \t73.5591\t2352.74\t2494.99\t2585.84\n",
      "5  \t10   \t73.5591\t2352.74\t2494.99\t2585.84\n",
      "6  \t10   \t73.5591\t2352.74\t2494.99\t2585.84\n",
      "7  \t10   \t73.1743\t2352.74\t2486.31\t2585.84\n",
      "8  \t10   \t92.4819\t2250.34\t2447.03\t2585.84\n",
      "9  \t10   \t103.985\t2250.34\t2410.86\t2585.84\n",
      "Best individual is  Individual('d', [0.5, 0.0, 0.25, 0.5559375, 0.4475, 0.15000000000000002, 0.9594999999999999, 0.3453125, 0.211, 0.267, 0.0, 1.0, 0.0, 0.3659375, 0.3, 0.08687500000000001, 0.29312499999999997, 0.1795, 0.03615625, 0.084125]) 2250.3404286085447\n",
      "gen\tevals\tstd    \tmin    \tavg    \tmax    \n",
      "0  \t10   \t414.508\t2477.62\t3109.72\t3843.89\n",
      "1  \t10   \t406.125\t2477.62\t3053.45\t3814.65\n",
      "2  \t10   \t313.798\t2477.62\t2939.67\t3419.88\n",
      "3  \t10   \t313.798\t2477.62\t2939.67\t3419.88\n",
      "4  \t10   \t323.884\t2477.62\t2925.67\t3419.88\n",
      "5  \t10   \t293.739\t2477.62\t2886.83\t3419.88\n",
      "6  \t10   \t234.698\t2477.62\t2834.03\t3151.7 \n",
      "7  \t10   \t193.874\t2477.62\t2783.66\t3044.16\n",
      "8  \t10   \t209.021\t2389.37\t2774.84\t3044.16\n",
      "9  \t10   \t165.051\t2389.37\t2658.64\t2925.02\n",
      "Best individual is  Individual('d', [0.9375, 0.0, 0.25, 0.5762499999999999, 0.51, 0.18, 0.8327500000000001, 0.3298125, 0.26975000000000005, 0.388, 0.0, 1.0, 0.0, 0.44, 0.34, 0.13375, 0.407, 0.209, 0.0735, 0.103]) 2389.3728533370795\n",
      "gen\tevals\tstd    \tmin    \tavg    \tmax    \n",
      "0  \t10   \t682.346\t2304.49\t2928.59\t4469.78\n",
      "1  \t10   \t514.461\t2304.49\t2759.8 \t3693.39\n",
      "2  \t10   \t401.581\t2304.49\t2675.45\t3342.96\n",
      "3  \t10   \t308.432\t2304.49\t2556.21\t3214.28\n",
      "4  \t10   \t300.034\t2304.49\t2543.84\t3196.12\n",
      "5  \t10   \t191.773\t2304.49\t2456.7 \t2944.86\n",
      "6  \t10   \t177.723\t2304.49\t2420.18\t2944.86\n",
      "7  \t10   \t178.496\t2304.49\t2413.55\t2942.76\n",
      "8  \t10   \t170.237\t2304.49\t2407.11\t2911.92\n",
      "9  \t10   \t152.901\t2304.49\t2388.89\t2841.53\n",
      "Best individual is  Individual('d', [0.0, 0.0, 1.0, 0.575, 0.46, 0.165, 0.9155, 0.4005, 0.2465, 0.2385, 0.0, 1.0, 0.0, 0.44, 0.355, 0.12, 0.495, 0.231, 0.11, 0.125]) 2304.4895664433398\n"
     ]
    }
   ],
   "source": [
    "H = 6\n",
    "clustering_centers = []\n",
    "for i in range(H):\n",
    "    clustering_centers.append(DE_clustering(0.6,0.5,10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take majority samples and compute for each of them their cluster stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifies sample x to the class which center is closer to\n",
    "def classify(x,centers):\n",
    "    dist_majcenter = euclidean(x,centers[:len(x)])\n",
    "    dist_mincenter = euclidean(x,centers[len(x):])\n",
    "    return np.argmin([dist_majcenter,dist_mincenter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.8333333333333334, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333334, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.8333333333333334, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.0, 0.8333333333333334, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.8333333333333334, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8333333333333334, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.6666666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8333333333333334, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.8333333333333334, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8333333333333334, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.8333333333333334, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8333333333333334, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.8333333333333334, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8333333333333334, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 0.8333333333333334, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.8333333333333334, 0.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8333333333333334, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8333333333333334, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8333333333333334, 0.8333333333333334, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8333333333333334, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8333333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8333333333333334, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.6666666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8333333333333334, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.8333333333333334, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8333333333333334, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8333333333333334, 0.0]\n"
     ]
    }
   ],
   "source": [
    "majority_samples = X_train[y_train==maj_class]\n",
    "\n",
    "cluster_stabilities = []\n",
    "for sample in majority_samples:\n",
    "    \n",
    "    S = 0\n",
    "    for clustering in clustering_centers:\n",
    "        c = classes[classify(sample,clustering)]\n",
    "        if c==maj_class:\n",
    "            S += 1\n",
    "    cluster_stabilities.append(S/H)\n",
    "\n",
    "print(cluster_stabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples in the majority class with the clustering stability value Ci higher than a given threshold alpha are non-bounday samples.\n",
    "We take alpha as 80% of the total clustering times (H???????????)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1012, 10)\n",
      "(1827, 10)\n"
     ]
    }
   ],
   "source": [
    "#alpha = H*0.8 ????????????????????\n",
    "alpha = 0.8\n",
    "boundary_points = majority_samples[np.array(cluster_stabilities)<=alpha]\n",
    "non_boundary_points = majority_samples[np.array(cluster_stabilities)>alpha]\n",
    "\n",
    "print(boundary_points.shape)\n",
    "print(non_boundary_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly under-sample the non boundary points of the majority class, giving more importance to the data distribution information in the under-sample process. (RUS puro o ponderando los ejemplos en base a su Ci?????????)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUÉ PROPORCIÓN DE LOS NON-BOUNDARY SELECCIONAMOS??????????'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 10)\n"
     ]
    }
   ],
   "source": [
    "#RUS PURO\n",
    "RUSsize = int(non_boundary_points.shape[0]*0.4)\n",
    "indices = np.random.randint(non_boundary_points.shape[0], size=RUSsize)\n",
    "nbp_us = non_boundary_points[indices]\n",
    "print(nbp_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 10)\n"
     ]
    }
   ],
   "source": [
    "#RUS ponderado por el cluster stability de cada ejemplo\n",
    "C_non_boundary = np.array(cluster_stabilities)[np.array(cluster_stabilities)>alpha]\n",
    "indices = np.random.choice(np.arange(non_boundary_points.shape[0]),size=RUSsize,\n",
    "                           p = C_non_boundary/sum(C_non_boundary))\n",
    "nbp_us = non_boundary_points[indices]\n",
    "print(nbp_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1742, 10)\n"
     ]
    }
   ],
   "source": [
    "new_majorityclass_training = np.vstack((boundary_points,nbp_us))\n",
    "print(new_majorityclass_training.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen del undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento original de tamaño: 3132\n",
      "De los cuales:\n",
      " \t nº de ejemplos clase MAYORITARIA: 2839\n",
      " \t nº de ejemplos clase MINORITARIA: 293\n",
      "CONJUNTO DE DATOS NO-BALANCEADO\n",
      "IR = 9.689419795221843\n",
      "nº de ejemplos clase MAYORITARIA tras aplicar DE-guided UNDERSAMPLING: 1742\n",
      "Conjunto de entrenamiento actual de tamaño: 2035\n"
     ]
    }
   ],
   "source": [
    "print(\"Conjunto de entrenamiento original de tamaño: {}\".format(X_train.shape[0]))\n",
    "n_may,n_min = sum(y_train == maj_class),sum(y_train == min_class)\n",
    "print(\"De los cuales:\\n \\t nº de ejemplos clase MAYORITARIA: {}\\n \\t nº de ejemplos clase MINORITARIA: {}\"\n",
    "      .format(n_may,n_min))\n",
    "print(\"CONJUNTO DE DATOS NO-BALANCEADO\")\n",
    "print(\"IR = {}\".format(n_may/n_min))\n",
    "\n",
    "print(\"nº de ejemplos clase MAYORITARIA tras aplicar DE-guided UNDERSAMPLING: {}\".format(new_majorityclass_training.shape[0]))\n",
    "print(\"Conjunto de entrenamiento actual de tamaño: {}\".format(new_majorityclass_training.shape[0]+n_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE-guided OVERSAMPLING of the minority class instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA-BOOST combined with DE-guided resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2035, 10) (2035,)\n"
     ]
    }
   ],
   "source": [
    "minority_samples = X_train[y_train==min_class]\n",
    "#prepare adaboost training set joining the undersampled majority class instances with the minority class instances\n",
    "X_US = np.vstack((new_majorityclass_training,minority_samples))\n",
    "y_US = np.hstack((np.full(new_majorityclass_training.shape[0],maj_class),\n",
    "                  np.full(minority_samples.shape[0],min_class)))\n",
    "print(X_US.shape,y_US.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate N = n_majority+n_minority weights\n",
    "#--> then we cant train DT in fitnesses with weigths bc syn samples dont have\n",
    "N = X_US.shape[0]\n",
    "weights = np.full(N,1/N)\n",
    "\n",
    "#print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate N = n_majority + 2*n_minority\n",
    "#N = minority_samples.shape[0]*2+new_majorityclass_training.shape[0]\n",
    "#w = np.full(N,1/N)\n",
    "\n",
    "#print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SMOTE to the original undersampled set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_synthetics(X,y,maj_class,min_class):\n",
    "    n_majority_samples = sum(y==maj_class)\n",
    "    n_minority_samples = sum(y==min_class)\n",
    "    print('Original dataset shape %s' % Counter(y))\n",
    "    sm = SMOTE(sampling_strategy = {maj_class: n_majority_samples,min_class: n_minority_samples*2})\n",
    "    X_after_SMOTE, y_after_SMOTE = sm.fit_resample(X, y)\n",
    "    print('Resampled dataset shape %s' % Counter(y_after_SMOTE))\n",
    "    synthetic_samples = X_after_SMOTE[y_after_SMOTE==min_class][n_minority_samples:]\n",
    "    #print('Synthetic samples: ',synthetic_samples)\n",
    "    return synthetic_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual = np.random.randint(0,2,size=minority_samples.shape[0])\n",
    "# print(individual)\n",
    "# print(sum(individual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_syn = synthetic_samples[individual>0]\n",
    "# print(selected_syn.shape)\n",
    "# Xtr = np.vstack((X_US,selected_syn))\n",
    "# print(Xtr.shape)\n",
    "# ytr = np.hstack((y_US,np.full(selected_syn.shape[0],min_class)))\n",
    "# print(ytr)\n",
    "# print(sum(ytr==min_class))\n",
    "# print(sum(ytr==maj_class))\n",
    "\n",
    "# #NO TENGO WEIGHTS PARA LOS SINTÉTICOS!!!!!!\n",
    "# select_w = np.hstack((np.full(X_US.shape[0],1),individual))\n",
    "\n",
    "\n",
    "# Xtr, Xtst, ytr, ytst = train_test_split(Xtr, ytr, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "# weights = np.full(Xtr.shape[0],1/Xtr.shape[0])\n",
    "# #dt = trainDT(Xtr,ytr,w[select_w>0])\n",
    "# dt = trainDT(Xtr,ytr)\n",
    "# #test??????????????????????????\n",
    "# G = Gmean(dt,Xtst,ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DE to select the best synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "# Xtr, Xtst, ytr, ytst = train_test_split(X_US, y_US, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "# weights = np.full(Xtr.shape[0],1/Xtr.shape[0])\n",
    "# dt = trainDT(Xtr,ytr,weights)\n",
    "# Gmean(dt,Xtst,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "def compute_fitness(p,X_before_SMOTE,y_before_SMOTE,maj_class,min_class,synthetic_samples, individual):\n",
    "    selected_syn = []\n",
    "    for i, value in enumerate(individual):\n",
    "        if individual[i]>0:\n",
    "            selected_syn.append(synthetic_samples[i-1])\n",
    "    #selected_syn = synthetic_samples[individual>0]\n",
    "    selected_syn = np.array(selected_syn)\n",
    "    Xtr = np.vstack((X_before_SMOTE,selected_syn))\n",
    "    ytr = np.hstack((y_before_SMOTE,np.full(selected_syn.shape[0],min_class)))\n",
    "    #realizar splitTest??????????????''\n",
    "    Xtr, Xtst, ytr, ytst = train_test_split(Xtr, ytr, test_size=0.3)\n",
    "    #dt = trainDT(Xtr,ytr,weights)\n",
    "    dt = trainDT(Xtr,ytr)\n",
    "    #test??????????????????????????\n",
    "    #G = Gmean(dt,X_before_SMOTE,y_before_SMOTE)\n",
    "    G = Gmean(dt,Xtst,ytst)\n",
    "    n_minority = len(individual)+sum(individual)\n",
    "    n_majority = X_before_SMOTE[y_before_SMOTE==maj_class].shape[0]\n",
    "    f = G - abs(1-(n_minority/n_majority*p))\n",
    "    #print(\"f: \",f)\n",
    "    return f,\n",
    "\n",
    "def trainDT(X_train,y_train,w=None):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train,y_train,sample_weight=w)\n",
    "    return clf\n",
    "\n",
    "def Gmean(clf,X_test,y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    gmean = geometric_mean_score(y_test, y_pred)\n",
    "    #print(\"Gmean:\",gmean)\n",
    "    return gmean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DE_oversampling(CR,F_0,POP_SIZE,NGEN):\n",
    "    # Differential evolution parameters\n",
    "    #CR = 0.25\n",
    "    #F = 1  \n",
    "    #MU = 300\n",
    "    #NGEN = 200    \n",
    "    \n",
    "    pop = toolbox.population(n=POP_SIZE);\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
    "    #print(pop)\n",
    "    # Evaluate the individuals\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, pop)\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, evals=len(pop), **record)\n",
    "    print(logbook.stream)\n",
    "    \n",
    "    for g in range(1, NGEN):\n",
    "        for k, agent in enumerate(pop):\n",
    "            a,b,c = toolbox.select(pop)\n",
    "            #we adopt a self-adaptative operator\n",
    "            l = math.exp(1-(NGEN/(NGEN+1-g)))\n",
    "            F = F_0*(2**l)\n",
    "            d = toolbox.clone(agent) #donor vector\n",
    "            sig_d = toolbox.clone(agent)\n",
    "            y = toolbox.clone(agent)\n",
    "            index = random.randrange(NDIM_DE_SMOTE)\n",
    "            for i, value in enumerate(agent):\n",
    "                d[i] = a[i] + F*(b[i]-c[i]) #donor vector\n",
    "                #the mutated donor is mapped to binary space by a sigmoid function with displacement\n",
    "                sig_d[i] = round(1/(1+math.exp(-(d[i]))))\n",
    "                if i == index or random.random() < CR:\n",
    "                    #y[i] = a[i] + F*(b[i]-c[i])\n",
    "                    y[i] = sig_d[i]\n",
    "            y.fitness.values = toolbox.evaluate(y)\n",
    "            if y.fitness > agent.fitness:\n",
    "                pop[k] = y\n",
    "            #print(pop[k].fitness)\n",
    "        hof.update(pop)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=g, evals=len(pop), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "    print(\"Best individual is \", hof[0], hof[0].fitness.values[0])\n",
    "    return hof[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristina/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/cristina/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin      \tavg      \tmax      \n",
      "0  \t10   \t0.0230694\t-0.314525\t-0.286835\t-0.239861\n",
      "1  \t10   \t0.0224066\t-0.294243\t-0.269607\t-0.233976\n",
      "2  \t10   \t0.021026 \t-0.28717 \t-0.259444\t-0.229162\n",
      "3  \t10   \t0.0183381\t-0.282709\t-0.255357\t-0.229162\n",
      "4  \t10   \t0.0219576\t-0.282709\t-0.250443\t-0.212905\n",
      "5  \t10   \t0.0226972\t-0.27772 \t-0.238958\t-0.203848\n",
      "6  \t10   \t0.0172979\t-0.262446\t-0.230631\t-0.203848\n",
      "7  \t10   \t0.014299 \t-0.241771\t-0.228499\t-0.203848\n",
      "8  \t10   \t0.0137334\t-0.241771\t-0.226041\t-0.203848\n",
      "9  \t10   \t0.012832 \t-0.241438\t-0.223666\t-0.203848\n",
      "10 \t10   \t0.0125894\t-0.239861\t-0.215227\t-0.198118\n",
      "11 \t10   \t0.013182 \t-0.239861\t-0.213551\t-0.198118\n",
      "12 \t10   \t0.0129094\t-0.234136\t-0.211285\t-0.197741\n",
      "13 \t10   \t0.0114715\t-0.234136\t-0.210332\t-0.197741\n",
      "14 \t10   \t0.0114394\t-0.234136\t-0.210058\t-0.197741\n",
      "15 \t10   \t0.0130583\t-0.234136\t-0.207939\t-0.189727\n",
      "16 \t10   \t0.0118761\t-0.234136\t-0.205803\t-0.189727\n",
      "17 \t10   \t0.0116151\t-0.233035\t-0.205693\t-0.189727\n",
      "18 \t10   \t0.0072401\t-0.21718 \t-0.202907\t-0.189727\n",
      "19 \t10   \t0.0072401\t-0.21718 \t-0.202907\t-0.189727\n",
      "20 \t10   \t0.0072401\t-0.21718 \t-0.202907\t-0.189727\n",
      "21 \t10   \t0.00723515\t-0.21718 \t-0.202748\t-0.189727\n",
      "22 \t10   \t0.0124159 \t-0.21718 \t-0.198561\t-0.171246\n",
      "23 \t10   \t0.0151097 \t-0.21718 \t-0.196711\t-0.158824\n",
      "24 \t10   \t0.0136362 \t-0.210161\t-0.195119\t-0.158824\n",
      "25 \t10   \t0.0132509 \t-0.210161\t-0.193176\t-0.158824\n",
      "26 \t10   \t0.0132509 \t-0.210161\t-0.193176\t-0.158824\n",
      "27 \t10   \t0.0132509 \t-0.210161\t-0.193176\t-0.158824\n",
      "28 \t10   \t0.0132509 \t-0.210161\t-0.193176\t-0.158824\n",
      "29 \t10   \t0.0132509 \t-0.210161\t-0.193176\t-0.158824\n",
      "30 \t10   \t0.0132408 \t-0.210161\t-0.192196\t-0.158824\n",
      "31 \t10   \t0.0160297 \t-0.210161\t-0.18484 \t-0.155494\n",
      "32 \t10   \t0.0160297 \t-0.210161\t-0.18484 \t-0.155494\n",
      "33 \t10   \t0.0160297 \t-0.210161\t-0.18484 \t-0.155494\n",
      "34 \t10   \t0.0160297 \t-0.210161\t-0.18484 \t-0.155494\n",
      "35 \t10   \t0.0160297 \t-0.210161\t-0.18484 \t-0.155494\n",
      "36 \t10   \t0.0160297 \t-0.210161\t-0.18484 \t-0.155494\n",
      "37 \t10   \t0.015434  \t-0.210161\t-0.183671\t-0.155494\n",
      "38 \t10   \t0.015431  \t-0.210161\t-0.182738\t-0.155494\n",
      "39 \t10   \t0.015431  \t-0.210161\t-0.182738\t-0.155494\n",
      "40 \t10   \t0.015431  \t-0.210161\t-0.182738\t-0.155494\n",
      "41 \t10   \t0.015431  \t-0.210161\t-0.182738\t-0.155494\n",
      "42 \t10   \t0.015431  \t-0.210161\t-0.182738\t-0.155494\n",
      "43 \t10   \t0.015431  \t-0.210161\t-0.182738\t-0.155494\n",
      "44 \t10   \t0.0146859 \t-0.210161\t-0.180377\t-0.155494\n",
      "45 \t10   \t0.0146859 \t-0.210161\t-0.180377\t-0.155494\n",
      "46 \t10   \t0.0145939 \t-0.210161\t-0.179454\t-0.155494\n",
      "47 \t10   \t0.0145939 \t-0.210161\t-0.179454\t-0.155494\n",
      "48 \t10   \t0.0144235 \t-0.208398\t-0.178561\t-0.155494\n",
      "49 \t10   \t0.0141608 \t-0.208398\t-0.177991\t-0.155494\n",
      "50 \t10   \t0.0141608 \t-0.208398\t-0.177991\t-0.155494\n",
      "51 \t10   \t0.0141608 \t-0.208398\t-0.177991\t-0.155494\n",
      "52 \t10   \t0.0141608 \t-0.208398\t-0.177991\t-0.155494\n",
      "53 \t10   \t0.0141608 \t-0.208398\t-0.177991\t-0.155494\n",
      "54 \t10   \t0.0129025 \t-0.202237\t-0.177374\t-0.155494\n",
      "55 \t10   \t0.0129025 \t-0.202237\t-0.177374\t-0.155494\n",
      "56 \t10   \t0.0129888 \t-0.202237\t-0.17694 \t-0.155494\n",
      "57 \t10   \t0.0126146 \t-0.200274\t-0.176744\t-0.155494\n",
      "58 \t10   \t0.0111065 \t-0.191043\t-0.175821\t-0.155494\n",
      "59 \t10   \t0.00994911\t-0.189727\t-0.173738\t-0.155494\n",
      "60 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "61 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "62 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "63 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "64 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "65 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "66 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "67 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "68 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "69 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "70 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "71 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "72 \t10   \t0.00987534\t-0.189727\t-0.173314\t-0.155494\n",
      "73 \t10   \t0.0102792 \t-0.189727\t-0.172458\t-0.155494\n",
      "74 \t10   \t0.0102792 \t-0.189727\t-0.172458\t-0.155494\n",
      "75 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "76 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "77 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "78 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "79 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "80 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "81 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "82 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "83 \t10   \t0.00961872\t-0.185444\t-0.172029\t-0.155494\n",
      "84 \t10   \t0.00924046\t-0.185444\t-0.171402\t-0.155494\n",
      "85 \t10   \t0.00916569\t-0.184946\t-0.171352\t-0.155494\n",
      "86 \t10   \t0.00916569\t-0.184946\t-0.171352\t-0.155494\n",
      "87 \t10   \t0.0123564 \t-0.184946\t-0.168713\t-0.143827\n",
      "88 \t10   \t0.0119963 \t-0.182005\t-0.168419\t-0.143827\n",
      "89 \t10   \t0.0119963 \t-0.182005\t-0.168419\t-0.143827\n",
      "90 \t10   \t0.0119963 \t-0.182005\t-0.168419\t-0.143827\n",
      "91 \t10   \t0.0119963 \t-0.182005\t-0.168419\t-0.143827\n",
      "92 \t10   \t0.0119963 \t-0.182005\t-0.168419\t-0.143827\n",
      "93 \t10   \t0.0119963 \t-0.182005\t-0.168419\t-0.143827\n",
      "94 \t10   \t0.0123456 \t-0.182005\t-0.167057\t-0.143827\n",
      "95 \t10   \t0.0121647 \t-0.182005\t-0.166902\t-0.143827\n",
      "96 \t10   \t0.0121647 \t-0.182005\t-0.166902\t-0.143827\n",
      "97 \t10   \t0.0121647 \t-0.182005\t-0.166902\t-0.143827\n",
      "98 \t10   \t0.0119163 \t-0.180443\t-0.16669 \t-0.143827\n",
      "99 \t10   \t0.0111125 \t-0.180443\t-0.165531\t-0.143827\n",
      "Best individual is  Individual('d', [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]) -0.14382725404082042\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin      \tavg     \tmax      \n",
      "0  \t10   \t0.0290249\t-0.321113\t-0.28476\t-0.220084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-145-0bf6e6d59a92>:39: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  w_clf = 0.5*math.log((1-e)/e)\n",
      "<ipython-input-145-0bf6e6d59a92>:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights = weights*np.exp(-w_clf*y_US*y_pred)/Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \t10   \t0.0211041\t-0.293089\t-0.270882\t-0.220084\n",
      "2  \t10   \t0.0167434\t-0.277198\t-0.253708\t-0.220084\n",
      "3  \t10   \t0.0189899\t-0.277198\t-0.23635 \t-0.20584 \n",
      "4  \t10   \t0.0203004\t-0.277198\t-0.231367\t-0.20584 \n",
      "5  \t10   \t0.0140627\t-0.24424 \t-0.224931\t-0.20584 \n",
      "6  \t10   \t0.0125128\t-0.241232\t-0.221459\t-0.200364\n",
      "7  \t10   \t0.00991314\t-0.234162\t-0.215883\t-0.200364\n",
      "8  \t10   \t0.00815484\t-0.224276\t-0.212914\t-0.200364\n",
      "9  \t10   \t0.00815484\t-0.224276\t-0.212914\t-0.200364\n",
      "10 \t10   \t0.0108693 \t-0.224276\t-0.211253\t-0.187779\n",
      "11 \t10   \t0.00963744\t-0.220084\t-0.209678\t-0.187779\n",
      "12 \t10   \t0.00963744\t-0.220084\t-0.209678\t-0.187779\n",
      "13 \t10   \t0.00951415\t-0.220084\t-0.208022\t-0.187779\n",
      "14 \t10   \t0.00951415\t-0.220084\t-0.208022\t-0.187779\n",
      "15 \t10   \t0.0111478 \t-0.220084\t-0.204717\t-0.184285\n",
      "16 \t10   \t0.0121751 \t-0.220084\t-0.204109\t-0.181691\n",
      "17 \t10   \t0.0115193 \t-0.217441\t-0.203527\t-0.181691\n",
      "18 \t10   \t0.0115193 \t-0.217441\t-0.203527\t-0.181691\n",
      "19 \t10   \t0.0115193 \t-0.217441\t-0.203527\t-0.181691\n",
      "20 \t10   \t0.0115193 \t-0.217441\t-0.203527\t-0.181691\n",
      "21 \t10   \t0.010984  \t-0.217441\t-0.202461\t-0.181691\n",
      "22 \t10   \t0.0108569 \t-0.217441\t-0.202067\t-0.181691\n",
      "23 \t10   \t0.0112394 \t-0.214268\t-0.198394\t-0.180719\n",
      "24 \t10   \t0.0112394 \t-0.214268\t-0.198394\t-0.180719\n",
      "25 \t10   \t0.011129  \t-0.214268\t-0.197495\t-0.180719\n",
      "26 \t10   \t0.0116155 \t-0.214268\t-0.195888\t-0.180719\n",
      "27 \t10   \t0.0100555 \t-0.208372\t-0.19449 \t-0.180719\n",
      "28 \t10   \t0.0100555 \t-0.208372\t-0.19449 \t-0.180719\n",
      "29 \t10   \t0.00983222\t-0.208372\t-0.189123\t-0.178423\n",
      "30 \t10   \t0.00983222\t-0.208372\t-0.189123\t-0.178423\n",
      "31 \t10   \t0.00983222\t-0.208372\t-0.189123\t-0.178423\n",
      "32 \t10   \t0.00983222\t-0.208372\t-0.189123\t-0.178423\n",
      "33 \t10   \t0.00983222\t-0.208372\t-0.189123\t-0.178423\n",
      "34 \t10   \t0.00983222\t-0.208372\t-0.189123\t-0.178423\n",
      "35 \t10   \t0.00941458\t-0.208372\t-0.188254\t-0.178423\n",
      "36 \t10   \t0.00941458\t-0.208372\t-0.188254\t-0.178423\n",
      "37 \t10   \t0.00754141\t-0.200279\t-0.182958\t-0.16967 \n",
      "38 \t10   \t0.00754141\t-0.200279\t-0.182958\t-0.16967 \n",
      "39 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "40 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "41 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "42 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "43 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "44 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "45 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "46 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "47 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "48 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "49 \t10   \t0.00744785\t-0.200279\t-0.182829\t-0.16967 \n",
      "50 \t10   \t0.00668474\t-0.192695\t-0.180585\t-0.16967 \n",
      "51 \t10   \t0.00668474\t-0.192695\t-0.180585\t-0.16967 \n",
      "52 \t10   \t0.00668474\t-0.192695\t-0.180585\t-0.16967 \n",
      "53 \t10   \t0.00668474\t-0.192695\t-0.180585\t-0.16967 \n",
      "54 \t10   \t0.00668474\t-0.192695\t-0.180585\t-0.16967 \n",
      "55 \t10   \t0.00668474\t-0.192695\t-0.180585\t-0.16967 \n",
      "56 \t10   \t0.00668474\t-0.192695\t-0.180585\t-0.16967 \n",
      "57 \t10   \t0.00562145\t-0.187667\t-0.179837\t-0.16967 \n",
      "58 \t10   \t0.00483285\t-0.18521 \t-0.178649\t-0.16967 \n",
      "59 \t10   \t0.00483285\t-0.18521 \t-0.178649\t-0.16967 \n",
      "60 \t10   \t0.00522459\t-0.18521 \t-0.177851\t-0.16967 \n",
      "61 \t10   \t0.00522459\t-0.18521 \t-0.177851\t-0.16967 \n",
      "62 \t10   \t0.00522459\t-0.18521 \t-0.177851\t-0.16967 \n",
      "63 \t10   \t0.00522459\t-0.18521 \t-0.177851\t-0.16967 \n",
      "64 \t10   \t0.00484413\t-0.182978\t-0.177526\t-0.16967 \n",
      "65 \t10   \t0.00484413\t-0.182978\t-0.177526\t-0.16967 \n",
      "66 \t10   \t0.00484413\t-0.182978\t-0.177526\t-0.16967 \n",
      "67 \t10   \t0.00484413\t-0.182978\t-0.177526\t-0.16967 \n",
      "68 \t10   \t0.00484413\t-0.182978\t-0.177526\t-0.16967 \n",
      "69 \t10   \t0.00484413\t-0.182978\t-0.177526\t-0.16967 \n",
      "70 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "71 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "72 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "73 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "74 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "75 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "76 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "77 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "78 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "79 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "80 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "81 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "82 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "83 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "84 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "85 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "86 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "87 \t10   \t0.00503831\t-0.182978\t-0.176954\t-0.16967 \n",
      "88 \t10   \t0.00462225\t-0.182556\t-0.176321\t-0.16967 \n",
      "89 \t10   \t0.00462225\t-0.182556\t-0.176321\t-0.16967 \n",
      "90 \t10   \t0.00462225\t-0.182556\t-0.176321\t-0.16967 \n",
      "91 \t10   \t0.00462225\t-0.182556\t-0.176321\t-0.16967 \n",
      "92 \t10   \t0.00462225\t-0.182556\t-0.176321\t-0.16967 \n",
      "93 \t10   \t0.00462225\t-0.182556\t-0.176321\t-0.16967 \n",
      "94 \t10   \t0.00462225\t-0.182556\t-0.176321\t-0.16967 \n",
      "95 \t10   \t0.00462225\t-0.182556\t-0.176321\t-0.16967 \n",
      "96 \t10   \t0.00573947\t-0.182556\t-0.17552 \t-0.16469 \n",
      "97 \t10   \t0.00573947\t-0.182556\t-0.17552 \t-0.16469 \n",
      "98 \t10   \t0.00544397\t-0.181962\t-0.175232\t-0.16469 \n",
      "99 \t10   \t0.00544397\t-0.181962\t-0.175232\t-0.16469 \n",
      "Best individual is  Individual('d', [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]) -0.16469031885538798\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin      \tavg      \tmax      \n",
      "0  \t10   \t0.0287874\t-0.339984\t-0.283259\t-0.235197\n",
      "1  \t10   \t0.0202567\t-0.300227\t-0.271982\t-0.235197\n",
      "2  \t10   \t0.02673  \t-0.282144\t-0.254381\t-0.200036\n",
      "3  \t10   \t0.0260131\t-0.277289\t-0.234632\t-0.193069\n",
      "4  \t10   \t0.0256183\t-0.277289\t-0.233642\t-0.193069\n",
      "5  \t10   \t0.0227016\t-0.267198\t-0.231553\t-0.193069\n",
      "6  \t10   \t0.0227016\t-0.267198\t-0.231553\t-0.193069\n",
      "7  \t10   \t0.0230238\t-0.267198\t-0.223236\t-0.193069\n",
      "8  \t10   \t0.021433 \t-0.243441\t-0.214433\t-0.177367\n",
      "9  \t10   \t0.0211547\t-0.243441\t-0.214195\t-0.177367\n",
      "10 \t10   \t0.0180345\t-0.243441\t-0.208355\t-0.177367\n",
      "11 \t10   \t0.0144799\t-0.222529\t-0.204281\t-0.177367\n",
      "12 \t10   \t0.0142486\t-0.222529\t-0.204068\t-0.177367\n",
      "13 \t10   \t0.0129076\t-0.221684\t-0.202418\t-0.177367\n",
      "14 \t10   \t0.0148037\t-0.221684\t-0.198835\t-0.177367\n",
      "15 \t10   \t0.0148037\t-0.221684\t-0.198835\t-0.177367\n",
      "16 \t10   \t0.0148088\t-0.221684\t-0.198789\t-0.177367\n",
      "17 \t10   \t0.0104647\t-0.209822\t-0.194511\t-0.177367\n",
      "18 \t10   \t0.011795 \t-0.209822\t-0.189607\t-0.167855\n",
      "19 \t10   \t0.011795 \t-0.209822\t-0.189607\t-0.167855\n",
      "20 \t10   \t0.011795 \t-0.209822\t-0.189607\t-0.167855\n",
      "21 \t10   \t0.0116683\t-0.209822\t-0.189369\t-0.167855\n",
      "22 \t10   \t0.010688 \t-0.204497\t-0.186263\t-0.167855\n",
      "23 \t10   \t0.010688 \t-0.204497\t-0.186263\t-0.167855\n",
      "24 \t10   \t0.010688 \t-0.204497\t-0.186263\t-0.167855\n",
      "25 \t10   \t0.01035  \t-0.204497\t-0.184314\t-0.167855\n",
      "26 \t10   \t0.01035  \t-0.204497\t-0.184314\t-0.167855\n",
      "27 \t10   \t0.01035  \t-0.204497\t-0.184314\t-0.167855\n",
      "28 \t10   \t0.01035  \t-0.204497\t-0.184314\t-0.167855\n",
      "29 \t10   \t0.0106595\t-0.204497\t-0.182643\t-0.167855\n",
      "30 \t10   \t0.0106595\t-0.204497\t-0.182643\t-0.167855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 \t10   \t0.0106595\t-0.204497\t-0.182643\t-0.167855\n",
      "32 \t10   \t0.0106595\t-0.204497\t-0.182643\t-0.167855\n",
      "33 \t10   \t0.0106595\t-0.204497\t-0.182643\t-0.167855\n",
      "34 \t10   \t0.010829 \t-0.204497\t-0.182524\t-0.166666\n",
      "35 \t10   \t0.010829 \t-0.204497\t-0.182524\t-0.166666\n",
      "36 \t10   \t0.010829 \t-0.204497\t-0.182524\t-0.166666\n",
      "37 \t10   \t0.0108058\t-0.204497\t-0.182452\t-0.166666\n",
      "38 \t10   \t0.0108058\t-0.204497\t-0.182452\t-0.166666\n",
      "39 \t10   \t0.0108058\t-0.204497\t-0.182452\t-0.166666\n",
      "40 \t10   \t0.0108058\t-0.204497\t-0.182452\t-0.166666\n",
      "41 \t10   \t0.0108058\t-0.204497\t-0.182452\t-0.166666\n",
      "42 \t10   \t0.0122649\t-0.204497\t-0.181268\t-0.161729\n",
      "43 \t10   \t0.0122649\t-0.204497\t-0.181268\t-0.161729\n",
      "44 \t10   \t0.0149738\t-0.204497\t-0.179   \t-0.152526\n",
      "45 \t10   \t0.0144051\t-0.201888\t-0.178349\t-0.152526\n",
      "46 \t10   \t0.013967 \t-0.201888\t-0.177733\t-0.152526\n",
      "47 \t10   \t0.0127339\t-0.200276\t-0.174825\t-0.152526\n",
      "48 \t10   \t0.0127339\t-0.200276\t-0.174825\t-0.152526\n",
      "49 \t10   \t0.0111167\t-0.191262\t-0.173923\t-0.152526\n",
      "50 \t10   \t0.0106735\t-0.191262\t-0.173362\t-0.152526\n",
      "51 \t10   \t0.0106735\t-0.191262\t-0.173362\t-0.152526\n",
      "52 \t10   \t0.0106735\t-0.191262\t-0.173362\t-0.152526\n",
      "53 \t10   \t0.0106735\t-0.191262\t-0.173362\t-0.152526\n",
      "54 \t10   \t0.0106735\t-0.191262\t-0.173362\t-0.152526\n",
      "55 \t10   \t0.0106735\t-0.191262\t-0.173362\t-0.152526\n",
      "56 \t10   \t0.0106735\t-0.191262\t-0.173362\t-0.152526\n",
      "57 \t10   \t0.0106735\t-0.191262\t-0.173362\t-0.152526\n",
      "58 \t10   \t0.010894 \t-0.191262\t-0.173066\t-0.152526\n",
      "59 \t10   \t0.010894 \t-0.191262\t-0.173066\t-0.152526\n",
      "60 \t10   \t0.0110662\t-0.191262\t-0.17128 \t-0.152526\n",
      "61 \t10   \t0.0110662\t-0.191262\t-0.17128 \t-0.152526\n",
      "62 \t10   \t0.0109179\t-0.191262\t-0.171112\t-0.152526\n",
      "63 \t10   \t0.0109179\t-0.191262\t-0.171112\t-0.152526\n",
      "64 \t10   \t0.0109179\t-0.191262\t-0.171112\t-0.152526\n",
      "65 \t10   \t0.0109179\t-0.191262\t-0.171112\t-0.152526\n",
      "66 \t10   \t0.0109179\t-0.191262\t-0.171112\t-0.152526\n",
      "67 \t10   \t0.0109179\t-0.191262\t-0.171112\t-0.152526\n",
      "68 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "69 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "70 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "71 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "72 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "73 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "74 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "75 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "76 \t10   \t0.0108573\t-0.191262\t-0.171035\t-0.152526\n",
      "77 \t10   \t0.010689 \t-0.191262\t-0.170635\t-0.152526\n",
      "78 \t10   \t0.010443 \t-0.189965\t-0.170505\t-0.152526\n",
      "79 \t10   \t0.010443 \t-0.189965\t-0.170505\t-0.152526\n",
      "80 \t10   \t0.010443 \t-0.189965\t-0.170505\t-0.152526\n",
      "81 \t10   \t0.010443 \t-0.189965\t-0.170505\t-0.152526\n",
      "82 \t10   \t0.0100238\t-0.189965\t-0.16956 \t-0.152526\n",
      "83 \t10   \t0.0100238\t-0.189965\t-0.16956 \t-0.152526\n",
      "84 \t10   \t0.0100238\t-0.189965\t-0.16956 \t-0.152526\n",
      "85 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "86 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "87 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "88 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "89 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "90 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "91 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "92 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "93 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "94 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "95 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "96 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "97 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "98 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "99 \t10   \t0.00846907\t-0.181242\t-0.168688\t-0.152526\n",
      "Best individual is  Individual('d', [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]) -0.15252573864208363\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin      \tavg      \tmax      \n",
      "0  \t10   \t0.0270179\t-0.348122\t-0.296889\t-0.251206\n",
      "1  \t10   \t0.0157523\t-0.290213\t-0.269983\t-0.236464\n",
      "2  \t10   \t0.0155475\t-0.281443\t-0.263899\t-0.236464\n",
      "3  \t10   \t0.0120842\t-0.275054\t-0.252893\t-0.236464\n",
      "4  \t10   \t0.0222103\t-0.261542\t-0.240474\t-0.183197\n",
      "5  \t10   \t0.0222565\t-0.258106\t-0.221315\t-0.183197\n",
      "6  \t10   \t0.0152664\t-0.235228\t-0.209504\t-0.183197\n",
      "7  \t10   \t0.0121001\t-0.22146 \t-0.201413\t-0.183197\n",
      "8  \t10   \t0.011368 \t-0.22146 \t-0.200607\t-0.183197\n",
      "9  \t10   \t0.0111929\t-0.22146 \t-0.20024 \t-0.183197\n",
      "10 \t10   \t0.0113088\t-0.22146 \t-0.197451\t-0.183197\n",
      "11 \t10   \t0.00853309\t-0.210546\t-0.195782\t-0.183197\n",
      "12 \t10   \t0.00853309\t-0.210546\t-0.195782\t-0.183197\n",
      "13 \t10   \t0.00853309\t-0.210546\t-0.195782\t-0.183197\n",
      "14 \t10   \t0.00701926\t-0.204767\t-0.193118\t-0.183197\n",
      "15 \t10   \t0.00701926\t-0.204767\t-0.193118\t-0.183197\n",
      "16 \t10   \t0.00701926\t-0.204767\t-0.193118\t-0.183197\n",
      "17 \t10   \t0.00701926\t-0.204767\t-0.193118\t-0.183197\n",
      "18 \t10   \t0.005878  \t-0.203971\t-0.191778\t-0.183197\n",
      "19 \t10   \t0.005878  \t-0.203971\t-0.191778\t-0.183197\n",
      "20 \t10   \t0.005878  \t-0.203971\t-0.191778\t-0.183197\n",
      "21 \t10   \t0.005878  \t-0.203971\t-0.191778\t-0.183197\n",
      "22 \t10   \t0.0047602 \t-0.199888\t-0.189707\t-0.183197\n",
      "23 \t10   \t0.0047602 \t-0.199888\t-0.189707\t-0.183197\n",
      "24 \t10   \t0.00490906\t-0.199888\t-0.189407\t-0.183197\n",
      "25 \t10   \t0.00490906\t-0.199888\t-0.189407\t-0.183197\n",
      "26 \t10   \t0.00490906\t-0.199888\t-0.189407\t-0.183197\n",
      "27 \t10   \t0.00490906\t-0.199888\t-0.189407\t-0.183197\n",
      "28 \t10   \t0.00490906\t-0.199888\t-0.189407\t-0.183197\n",
      "29 \t10   \t0.00482045\t-0.199469\t-0.189365\t-0.183197\n",
      "30 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "31 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "32 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "33 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "34 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "35 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "36 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "37 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "38 \t10   \t0.00385668\t-0.193997\t-0.188818\t-0.183197\n",
      "39 \t10   \t0.00584933\t-0.193267\t-0.186668\t-0.172495\n",
      "40 \t10   \t0.00768805\t-0.193267\t-0.184399\t-0.168704\n",
      "41 \t10   \t0.00768805\t-0.193267\t-0.184399\t-0.168704\n",
      "42 \t10   \t0.00768805\t-0.193267\t-0.184399\t-0.168704\n",
      "43 \t10   \t0.00789188\t-0.193267\t-0.182825\t-0.168704\n",
      "44 \t10   \t0.00789188\t-0.193267\t-0.182825\t-0.168704\n",
      "45 \t10   \t0.00789188\t-0.193267\t-0.182825\t-0.168704\n",
      "46 \t10   \t0.00789188\t-0.193267\t-0.182825\t-0.168704\n",
      "47 \t10   \t0.00730115\t-0.193267\t-0.181628\t-0.168704\n",
      "48 \t10   \t0.00762599\t-0.193267\t-0.181451\t-0.166937\n",
      "49 \t10   \t0.00762599\t-0.193267\t-0.181451\t-0.166937\n",
      "50 \t10   \t0.00762599\t-0.193267\t-0.181451\t-0.166937\n",
      "51 \t10   \t0.00748368\t-0.193267\t-0.181302\t-0.166937\n",
      "52 \t10   \t0.00779917\t-0.193267\t-0.180999\t-0.166937\n",
      "53 \t10   \t0.00758115\t-0.193267\t-0.180692\t-0.166937\n",
      "54 \t10   \t0.00758115\t-0.193267\t-0.180692\t-0.166937\n",
      "55 \t10   \t0.00744354\t-0.193267\t-0.180412\t-0.166937\n",
      "56 \t10   \t0.00744354\t-0.193267\t-0.180412\t-0.166937\n",
      "57 \t10   \t0.00723675\t-0.193267\t-0.179783\t-0.166937\n",
      "58 \t10   \t0.00723675\t-0.193267\t-0.179783\t-0.166937\n",
      "59 \t10   \t0.00723675\t-0.193267\t-0.179783\t-0.166937\n",
      "60 \t10   \t0.00723675\t-0.193267\t-0.179783\t-0.166937\n",
      "61 \t10   \t0.00570587\t-0.184786\t-0.178492\t-0.166937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 \t10   \t0.00570587\t-0.184786\t-0.178492\t-0.166937\n",
      "63 \t10   \t0.00570587\t-0.184786\t-0.178492\t-0.166937\n",
      "64 \t10   \t0.00570587\t-0.184786\t-0.178492\t-0.166937\n",
      "65 \t10   \t0.00570587\t-0.184786\t-0.178492\t-0.166937\n",
      "66 \t10   \t0.00570587\t-0.184786\t-0.178492\t-0.166937\n",
      "67 \t10   \t0.00580544\t-0.184786\t-0.177337\t-0.166937\n",
      "68 \t10   \t0.00694783\t-0.184786\t-0.17582 \t-0.164191\n",
      "69 \t10   \t0.00694783\t-0.184786\t-0.17582 \t-0.164191\n",
      "70 \t10   \t0.00694783\t-0.184786\t-0.17582 \t-0.164191\n",
      "71 \t10   \t0.00694783\t-0.184786\t-0.17582 \t-0.164191\n",
      "72 \t10   \t0.00694783\t-0.184786\t-0.17582 \t-0.164191\n",
      "73 \t10   \t0.00694783\t-0.184786\t-0.17582 \t-0.164191\n",
      "74 \t10   \t0.0068167 \t-0.184786\t-0.175475\t-0.164191\n",
      "75 \t10   \t0.0068167 \t-0.184786\t-0.175475\t-0.164191\n",
      "76 \t10   \t0.00675628\t-0.184786\t-0.175421\t-0.164191\n",
      "77 \t10   \t0.00675628\t-0.184786\t-0.175421\t-0.164191\n",
      "78 \t10   \t0.00675628\t-0.184786\t-0.175421\t-0.164191\n",
      "79 \t10   \t0.00649151\t-0.184786\t-0.175127\t-0.164191\n",
      "80 \t10   \t0.00636906\t-0.184786\t-0.175018\t-0.164191\n",
      "81 \t10   \t0.00636906\t-0.184786\t-0.175018\t-0.164191\n",
      "82 \t10   \t0.00636906\t-0.184786\t-0.175018\t-0.164191\n",
      "83 \t10   \t0.00636906\t-0.184786\t-0.175018\t-0.164191\n",
      "84 \t10   \t0.00636906\t-0.184786\t-0.175018\t-0.164191\n",
      "85 \t10   \t0.00636906\t-0.184786\t-0.175018\t-0.164191\n",
      "86 \t10   \t0.00636906\t-0.184786\t-0.175018\t-0.164191\n",
      "87 \t10   \t0.00697297\t-0.181757\t-0.172492\t-0.159533\n",
      "88 \t10   \t0.00697297\t-0.181757\t-0.172492\t-0.159533\n",
      "89 \t10   \t0.00697297\t-0.181757\t-0.172492\t-0.159533\n",
      "90 \t10   \t0.00697297\t-0.181757\t-0.172492\t-0.159533\n",
      "91 \t10   \t0.00697297\t-0.181757\t-0.172492\t-0.159533\n",
      "92 \t10   \t0.00697297\t-0.181757\t-0.172492\t-0.159533\n",
      "93 \t10   \t0.00741553\t-0.180361\t-0.170134\t-0.158169\n",
      "94 \t10   \t0.00746049\t-0.180361\t-0.169493\t-0.158169\n",
      "95 \t10   \t0.00746049\t-0.180361\t-0.169493\t-0.158169\n",
      "96 \t10   \t0.00752297\t-0.180361\t-0.169374\t-0.158169\n",
      "97 \t10   \t0.00752297\t-0.180361\t-0.169374\t-0.158169\n",
      "98 \t10   \t0.00752297\t-0.180361\t-0.169374\t-0.158169\n",
      "99 \t10   \t0.00752297\t-0.180361\t-0.169374\t-0.158169\n",
      "Best individual is  Individual('d', [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]) -0.15816939623598147\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin      \tavg      \tmax      \n",
      "0  \t10   \t0.0189242\t-0.329939\t-0.298597\t-0.276346\n",
      "1  \t10   \t0.0176125\t-0.318887\t-0.280491\t-0.256693\n",
      "2  \t10   \t0.0168993\t-0.276902\t-0.256871\t-0.228962\n",
      "3  \t10   \t0.0169858\t-0.272403\t-0.251925\t-0.228875\n",
      "4  \t10   \t0.0165051\t-0.271582\t-0.249399\t-0.228875\n",
      "5  \t10   \t0.016015 \t-0.271582\t-0.24795 \t-0.228875\n",
      "6  \t10   \t0.0131924\t-0.271582\t-0.239781\t-0.224899\n",
      "7  \t10   \t0.00978408\t-0.245303\t-0.23203 \t-0.211313\n",
      "8  \t10   \t0.0135365 \t-0.245303\t-0.223985\t-0.206172\n",
      "9  \t10   \t0.0140271 \t-0.245303\t-0.221107\t-0.206172\n",
      "10 \t10   \t0.0123155 \t-0.245303\t-0.218467\t-0.206172\n",
      "11 \t10   \t0.0120213 \t-0.243938\t-0.21833 \t-0.206172\n",
      "12 \t10   \t0.0127997 \t-0.243938\t-0.217078\t-0.203729\n",
      "13 \t10   \t0.0118077 \t-0.237158\t-0.2128  \t-0.192259\n",
      "14 \t10   \t0.0161685 \t-0.237158\t-0.20556 \t-0.174346\n",
      "15 \t10   \t0.0141351 \t-0.225457\t-0.20439 \t-0.174346\n",
      "16 \t10   \t0.0133043 \t-0.225457\t-0.203615\t-0.174346\n",
      "17 \t10   \t0.0120985 \t-0.216906\t-0.202487\t-0.174346\n",
      "18 \t10   \t0.0129112 \t-0.216906\t-0.201739\t-0.174346\n",
      "19 \t10   \t0.0125004 \t-0.216906\t-0.199932\t-0.174346\n",
      "20 \t10   \t0.0125004 \t-0.216906\t-0.199932\t-0.174346\n",
      "21 \t10   \t0.0119686 \t-0.216906\t-0.199414\t-0.174346\n",
      "22 \t10   \t0.0115099 \t-0.216906\t-0.19859 \t-0.174346\n",
      "23 \t10   \t0.0107017 \t-0.211209\t-0.19802 \t-0.174346\n",
      "24 \t10   \t0.0107017 \t-0.211209\t-0.19802 \t-0.174346\n",
      "25 \t10   \t0.0107017 \t-0.211209\t-0.19802 \t-0.174346\n",
      "26 \t10   \t0.00955168\t-0.208895\t-0.196621\t-0.174346\n",
      "27 \t10   \t0.00939945\t-0.208895\t-0.196184\t-0.174346\n",
      "28 \t10   \t0.0100669 \t-0.208895\t-0.194149\t-0.174346\n",
      "29 \t10   \t0.0108759 \t-0.201855\t-0.18878 \t-0.172956\n",
      "30 \t10   \t0.0108759 \t-0.201855\t-0.18878 \t-0.172956\n",
      "31 \t10   \t0.0108759 \t-0.201855\t-0.18878 \t-0.172956\n",
      "32 \t10   \t0.0100644 \t-0.201855\t-0.187089\t-0.172956\n",
      "33 \t10   \t0.00982099\t-0.201855\t-0.18568 \t-0.172956\n",
      "34 \t10   \t0.00982099\t-0.201855\t-0.18568 \t-0.172956\n",
      "35 \t10   \t0.00687218\t-0.194687\t-0.183598\t-0.172956\n",
      "36 \t10   \t0.00687218\t-0.194687\t-0.183598\t-0.172956\n",
      "37 \t10   \t0.00687218\t-0.194687\t-0.183598\t-0.172956\n",
      "38 \t10   \t0.00687218\t-0.194687\t-0.183598\t-0.172956\n",
      "39 \t10   \t0.00687218\t-0.194687\t-0.183598\t-0.172956\n",
      "40 \t10   \t0.00687218\t-0.194687\t-0.183598\t-0.172956\n",
      "41 \t10   \t0.00686624\t-0.194687\t-0.183557\t-0.172956\n",
      "42 \t10   \t0.00686624\t-0.194687\t-0.183557\t-0.172956\n",
      "43 \t10   \t0.00686624\t-0.194687\t-0.183557\t-0.172956\n",
      "44 \t10   \t0.00587632\t-0.191749\t-0.181963\t-0.172956\n",
      "45 \t10   \t0.00587632\t-0.191749\t-0.181963\t-0.172956\n",
      "46 \t10   \t0.00546008\t-0.190783\t-0.180065\t-0.172765\n",
      "47 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "48 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "49 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "50 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "51 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "52 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "53 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "54 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "55 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "56 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "57 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "58 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "59 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "60 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "61 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "62 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "63 \t10   \t0.00550202\t-0.190783\t-0.179703\t-0.172765\n",
      "64 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "65 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "66 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "67 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "68 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "69 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "70 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "71 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "72 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "73 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "74 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "75 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "76 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "77 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "78 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "79 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "80 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "81 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "82 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "83 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "84 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "85 \t10   \t0.00703449\t-0.190783\t-0.177942\t-0.164562\n",
      "86 \t10   \t0.00719687\t-0.190783\t-0.177435\t-0.164562\n",
      "87 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n",
      "88 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n",
      "89 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n",
      "91 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n",
      "92 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n",
      "93 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n",
      "94 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n",
      "95 \t10   \t0.00841687\t-0.190783\t-0.175287\t-0.161187\n",
      "96 \t10   \t0.0078304 \t-0.184503\t-0.172185\t-0.15976 \n",
      "97 \t10   \t0.0078304 \t-0.184503\t-0.172185\t-0.15976 \n",
      "98 \t10   \t0.0078304 \t-0.184503\t-0.172185\t-0.15976 \n",
      "99 \t10   \t0.0078304 \t-0.184503\t-0.172185\t-0.15976 \n",
      "Best individual is  Individual('d', [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]) -0.15976018374115175\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin      \tavg      \tmax      \n",
      "0  \t10   \t0.0264783\t-0.323367\t-0.289219\t-0.238332\n",
      "1  \t10   \t0.0259682\t-0.323367\t-0.277022\t-0.238332\n",
      "2  \t10   \t0.0212553\t-0.307429\t-0.263776\t-0.236721\n",
      "3  \t10   \t0.0155413\t-0.266856\t-0.24366 \t-0.214043\n",
      "4  \t10   \t0.0195162\t-0.266856\t-0.23497 \t-0.206382\n",
      "5  \t10   \t0.0146832\t-0.259268\t-0.229626\t-0.206382\n",
      "6  \t10   \t0.0137853\t-0.255158\t-0.228274\t-0.206382\n",
      "7  \t10   \t0.013808 \t-0.25273 \t-0.227644\t-0.204279\n",
      "8  \t10   \t0.0113881\t-0.236721\t-0.220777\t-0.204279\n",
      "9  \t10   \t0.0113881\t-0.236721\t-0.220777\t-0.204279\n",
      "10 \t10   \t0.0156969\t-0.236721\t-0.218492\t-0.182675\n",
      "11 \t10   \t0.0148217\t-0.236721\t-0.216734\t-0.182675\n",
      "12 \t10   \t0.0147561\t-0.236721\t-0.215542\t-0.182675\n",
      "13 \t10   \t0.0147561\t-0.236721\t-0.215542\t-0.182675\n",
      "14 \t10   \t0.0144109\t-0.236721\t-0.214756\t-0.182675\n",
      "15 \t10   \t0.0144284\t-0.236721\t-0.214732\t-0.182675\n",
      "16 \t10   \t0.0142486\t-0.236721\t-0.214594\t-0.182675\n",
      "17 \t10   \t0.0174207\t-0.236721\t-0.210341\t-0.180494\n",
      "18 \t10   \t0.0174207\t-0.236721\t-0.210341\t-0.180494\n",
      "19 \t10   \t0.0174207\t-0.236721\t-0.210341\t-0.180494\n",
      "20 \t10   \t0.0171187\t-0.236721\t-0.209091\t-0.180494\n",
      "21 \t10   \t0.0144522\t-0.232619\t-0.206287\t-0.180494\n",
      "22 \t10   \t0.0127635\t-0.221945\t-0.20522 \t-0.180494\n",
      "23 \t10   \t0.0164561\t-0.221945\t-0.201886\t-0.170702\n",
      "24 \t10   \t0.0148083\t-0.216861\t-0.19936 \t-0.170702\n",
      "25 \t10   \t0.0162479\t-0.216861\t-0.196111\t-0.170702\n",
      "26 \t10   \t0.0162479\t-0.216861\t-0.196111\t-0.170702\n",
      "27 \t10   \t0.0162479\t-0.216861\t-0.196111\t-0.170702\n",
      "28 \t10   \t0.014601 \t-0.20982 \t-0.19434 \t-0.170702\n",
      "29 \t10   \t0.0136592\t-0.20868 \t-0.192587\t-0.170702\n",
      "30 \t10   \t0.0136592\t-0.20868 \t-0.192587\t-0.170702\n",
      "31 \t10   \t0.0136592\t-0.20868 \t-0.192587\t-0.170702\n",
      "32 \t10   \t0.0136592\t-0.20868 \t-0.192587\t-0.170702\n",
      "33 \t10   \t0.0129625\t-0.20868 \t-0.190179\t-0.170702\n",
      "34 \t10   \t0.0129625\t-0.20868 \t-0.190179\t-0.170702\n",
      "35 \t10   \t0.0132386\t-0.20868 \t-0.189855\t-0.170702\n",
      "36 \t10   \t0.0132386\t-0.20868 \t-0.189855\t-0.170702\n",
      "37 \t10   \t0.0132386\t-0.20868 \t-0.189855\t-0.170702\n",
      "38 \t10   \t0.0132386\t-0.20868 \t-0.189855\t-0.170702\n",
      "39 \t10   \t0.0132386\t-0.20868 \t-0.189855\t-0.170702\n",
      "40 \t10   \t0.0127871\t-0.207165\t-0.187239\t-0.170702\n",
      "41 \t10   \t0.013134 \t-0.207165\t-0.185532\t-0.170702\n",
      "42 \t10   \t0.013134 \t-0.207165\t-0.185532\t-0.170702\n",
      "43 \t10   \t0.013134 \t-0.207165\t-0.185532\t-0.170702\n",
      "44 \t10   \t0.0112766\t-0.207165\t-0.183877\t-0.170702\n",
      "45 \t10   \t0.0112766\t-0.207165\t-0.183877\t-0.170702\n",
      "46 \t10   \t0.0112766\t-0.207165\t-0.183877\t-0.170702\n",
      "47 \t10   \t0.0110328\t-0.207165\t-0.183703\t-0.170702\n",
      "48 \t10   \t0.0110328\t-0.207165\t-0.183703\t-0.170702\n",
      "49 \t10   \t0.00929641\t-0.198514\t-0.182791\t-0.170702\n",
      "50 \t10   \t0.00929641\t-0.198514\t-0.182791\t-0.170702\n",
      "51 \t10   \t0.00948446\t-0.198514\t-0.182177\t-0.170702\n",
      "52 \t10   \t0.00999762\t-0.198514\t-0.181116\t-0.169262\n",
      "53 \t10   \t0.00999762\t-0.198514\t-0.181116\t-0.169262\n",
      "54 \t10   \t0.00999762\t-0.198514\t-0.181116\t-0.169262\n",
      "55 \t10   \t0.0105083 \t-0.198514\t-0.180373\t-0.168592\n",
      "56 \t10   \t0.00992056\t-0.198049\t-0.180009\t-0.168592\n",
      "57 \t10   \t0.00992056\t-0.198049\t-0.180009\t-0.168592\n",
      "58 \t10   \t0.00992056\t-0.198049\t-0.180009\t-0.168592\n",
      "59 \t10   \t0.00998076\t-0.198049\t-0.179864\t-0.168592\n",
      "60 \t10   \t0.00998076\t-0.198049\t-0.179864\t-0.168592\n",
      "61 \t10   \t0.00998076\t-0.198049\t-0.179864\t-0.168592\n",
      "62 \t10   \t0.00998076\t-0.198049\t-0.179864\t-0.168592\n",
      "63 \t10   \t0.0107126 \t-0.198049\t-0.178317\t-0.166461\n",
      "64 \t10   \t0.0107126 \t-0.198049\t-0.178317\t-0.166461\n",
      "65 \t10   \t0.0107126 \t-0.198049\t-0.178317\t-0.166461\n",
      "66 \t10   \t0.0107126 \t-0.198049\t-0.178317\t-0.166461\n",
      "67 \t10   \t0.0103824 \t-0.198049\t-0.178093\t-0.166461\n",
      "68 \t10   \t0.0103824 \t-0.198049\t-0.178093\t-0.166461\n",
      "69 \t10   \t0.00878774\t-0.192638\t-0.177109\t-0.166461\n",
      "70 \t10   \t0.00878774\t-0.192638\t-0.177109\t-0.166461\n",
      "71 \t10   \t0.00878774\t-0.192638\t-0.177109\t-0.166461\n",
      "72 \t10   \t0.00878774\t-0.192638\t-0.177109\t-0.166461\n",
      "73 \t10   \t0.00878774\t-0.192638\t-0.177109\t-0.166461\n",
      "74 \t10   \t0.00878774\t-0.192638\t-0.177109\t-0.166461\n",
      "75 \t10   \t0.00828185\t-0.192638\t-0.175128\t-0.166461\n",
      "76 \t10   \t0.00828185\t-0.192638\t-0.175128\t-0.166461\n",
      "77 \t10   \t0.00828185\t-0.192638\t-0.175128\t-0.166461\n",
      "78 \t10   \t0.00828185\t-0.192638\t-0.175128\t-0.166461\n",
      "79 \t10   \t0.00828185\t-0.192638\t-0.175128\t-0.166461\n",
      "80 \t10   \t0.00828185\t-0.192638\t-0.175128\t-0.166461\n",
      "81 \t10   \t0.00736287\t-0.192638\t-0.174323\t-0.166461\n",
      "82 \t10   \t0.00565697\t-0.185223\t-0.173581\t-0.166461\n",
      "83 \t10   \t0.00565697\t-0.185223\t-0.173581\t-0.166461\n",
      "84 \t10   \t0.00564656\t-0.185223\t-0.173536\t-0.166461\n",
      "85 \t10   \t0.00564656\t-0.185223\t-0.173536\t-0.166461\n",
      "86 \t10   \t0.00564656\t-0.185223\t-0.173536\t-0.166461\n",
      "87 \t10   \t0.00564656\t-0.185223\t-0.173536\t-0.166461\n",
      "88 \t10   \t0.00564656\t-0.185223\t-0.173536\t-0.166461\n",
      "89 \t10   \t0.00564656\t-0.185223\t-0.173536\t-0.166461\n",
      "90 \t10   \t0.00548989\t-0.185223\t-0.173374\t-0.166461\n",
      "91 \t10   \t0.00548989\t-0.185223\t-0.173374\t-0.166461\n",
      "92 \t10   \t0.00548989\t-0.185223\t-0.173374\t-0.166461\n",
      "93 \t10   \t0.00548989\t-0.185223\t-0.173374\t-0.166461\n",
      "94 \t10   \t0.00503219\t-0.183004\t-0.173152\t-0.166461\n",
      "95 \t10   \t0.00503219\t-0.183004\t-0.173152\t-0.166461\n",
      "96 \t10   \t0.00503219\t-0.183004\t-0.173152\t-0.166461\n",
      "97 \t10   \t0.00503219\t-0.183004\t-0.173152\t-0.166461\n",
      "98 \t10   \t0.0102653 \t-0.183004\t-0.169581\t-0.142304\n",
      "99 \t10   \t0.0102653 \t-0.183004\t-0.169581\t-0.142304\n",
      "Best individual is  Individual('d', [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]) -0.14230388597939858\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tevals\tstd      \tmin      \tavg      \tmax      \n",
      "0  \t10   \t0.0338489\t-0.349223\t-0.297038\t-0.241108\n",
      "1  \t10   \t0.0246539\t-0.324672\t-0.276139\t-0.241108\n",
      "2  \t10   \t0.018748 \t-0.288514\t-0.252153\t-0.225017\n",
      "3  \t10   \t0.0307779\t-0.288514\t-0.237806\t-0.174551\n",
      "4  \t10   \t0.0271264\t-0.262008\t-0.226681\t-0.174551\n",
      "5  \t10   \t0.025768 \t-0.262008\t-0.225073\t-0.174551\n",
      "6  \t10   \t0.0229334\t-0.254377\t-0.220827\t-0.174551\n",
      "7  \t10   \t0.0210917\t-0.254377\t-0.21493 \t-0.174551\n",
      "8  \t10   \t0.0201007\t-0.251098\t-0.21355 \t-0.174551\n",
      "9  \t10   \t0.0201007\t-0.251098\t-0.21355 \t-0.174551\n",
      "10 \t10   \t0.0198355\t-0.232422\t-0.208181\t-0.174551\n",
      "11 \t10   \t0.0198355\t-0.232422\t-0.208181\t-0.174551\n",
      "12 \t10   \t0.0188969\t-0.232422\t-0.204909\t-0.174551\n",
      "13 \t10   \t0.0188969\t-0.232422\t-0.204909\t-0.174551\n",
      "14 \t10   \t0.0166065\t-0.229451\t-0.201035\t-0.174551\n",
      "15 \t10   \t0.0133374\t-0.216383\t-0.197799\t-0.174551\n",
      "16 \t10   \t0.0133374\t-0.216383\t-0.197799\t-0.174551\n",
      "17 \t10   \t0.0118914\t-0.215737\t-0.195275\t-0.174551\n",
      "18 \t10   \t0.0118914\t-0.215737\t-0.195275\t-0.174551\n",
      "19 \t10   \t0.0118914\t-0.215737\t-0.195275\t-0.174551\n",
      "20 \t10   \t0.0118914\t-0.215737\t-0.195275\t-0.174551\n",
      "21 \t10   \t0.0115547\t-0.215737\t-0.194497\t-0.174551\n",
      "22 \t10   \t0.0121195\t-0.215737\t-0.192956\t-0.174551\n",
      "23 \t10   \t0.0121195\t-0.215737\t-0.192956\t-0.174551\n",
      "24 \t10   \t0.0118166\t-0.215737\t-0.192516\t-0.174551\n",
      "25 \t10   \t0.0118096\t-0.215701\t-0.192512\t-0.174551\n",
      "26 \t10   \t0.0117677\t-0.215701\t-0.192051\t-0.174551\n",
      "27 \t10   \t0.0117727\t-0.215701\t-0.191999\t-0.174551\n",
      "28 \t10   \t0.0117937\t-0.215701\t-0.191848\t-0.174551\n",
      "29 \t10   \t0.0114868\t-0.214159\t-0.191694\t-0.174551\n",
      "30 \t10   \t0.0114868\t-0.214159\t-0.191694\t-0.174551\n",
      "31 \t10   \t0.0114868\t-0.214159\t-0.191694\t-0.174551\n",
      "32 \t10   \t0.0114868\t-0.214159\t-0.191694\t-0.174551\n",
      "33 \t10   \t0.00897927\t-0.201806\t-0.189924\t-0.174551\n",
      "34 \t10   \t0.00897927\t-0.201806\t-0.189924\t-0.174551\n",
      "35 \t10   \t0.00897927\t-0.201806\t-0.189924\t-0.174551\n",
      "36 \t10   \t0.00897927\t-0.201806\t-0.189924\t-0.174551\n",
      "37 \t10   \t0.00954883\t-0.201806\t-0.187275\t-0.173695\n",
      "38 \t10   \t0.00950008\t-0.201806\t-0.187091\t-0.173695\n",
      "39 \t10   \t0.00950008\t-0.201806\t-0.187091\t-0.173695\n",
      "40 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "41 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "42 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "43 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "44 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "45 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "46 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "47 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "48 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "49 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "50 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "51 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "52 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "53 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "54 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "55 \t10   \t0.00957524\t-0.201806\t-0.184933\t-0.173695\n",
      "56 \t10   \t0.00892904\t-0.201806\t-0.184042\t-0.173695\n",
      "57 \t10   \t0.00892904\t-0.201806\t-0.184042\t-0.173695\n",
      "58 \t10   \t0.00892904\t-0.201806\t-0.184042\t-0.173695\n",
      "59 \t10   \t0.00892904\t-0.201806\t-0.184042\t-0.173695\n",
      "60 \t10   \t0.00926801\t-0.201806\t-0.183423\t-0.173695\n",
      "61 \t10   \t0.00926801\t-0.201806\t-0.183423\t-0.173695\n",
      "62 \t10   \t0.00926801\t-0.201806\t-0.183423\t-0.173695\n",
      "63 \t10   \t0.0086486 \t-0.198524\t-0.183095\t-0.173695\n",
      "64 \t10   \t0.0086486 \t-0.198524\t-0.183095\t-0.173695\n",
      "65 \t10   \t0.0086486 \t-0.198524\t-0.183095\t-0.173695\n",
      "66 \t10   \t0.0086486 \t-0.198524\t-0.183095\t-0.173695\n",
      "67 \t10   \t0.0086486 \t-0.198524\t-0.183095\t-0.173695\n",
      "68 \t10   \t0.0086486 \t-0.198524\t-0.183095\t-0.173695\n",
      "69 \t10   \t0.0086486 \t-0.198524\t-0.183095\t-0.173695\n",
      "70 \t10   \t0.00920465\t-0.198524\t-0.181564\t-0.171432\n",
      "71 \t10   \t0.00900634\t-0.198524\t-0.181386\t-0.171432\n",
      "72 \t10   \t0.00900634\t-0.198524\t-0.181386\t-0.171432\n",
      "73 \t10   \t0.00900634\t-0.198524\t-0.181386\t-0.171432\n",
      "74 \t10   \t0.00900634\t-0.198524\t-0.181386\t-0.171432\n",
      "75 \t10   \t0.00900634\t-0.198524\t-0.181386\t-0.171432\n",
      "76 \t10   \t0.00900634\t-0.198524\t-0.181386\t-0.171432\n",
      "77 \t10   \t0.00877452\t-0.198524\t-0.17988 \t-0.171432\n",
      "78 \t10   \t0.00877452\t-0.198524\t-0.17988 \t-0.171432\n",
      "79 \t10   \t0.00659301\t-0.190762\t-0.177056\t-0.170282\n",
      "80 \t10   \t0.00659301\t-0.190762\t-0.177056\t-0.170282\n",
      "81 \t10   \t0.00659301\t-0.190762\t-0.177056\t-0.170282\n",
      "82 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "83 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "84 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "85 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "86 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "87 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "88 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "89 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "90 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "91 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "92 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "93 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "94 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "95 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "96 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "97 \t10   \t0.00535084\t-0.190762\t-0.175535\t-0.170282\n",
      "98 \t10   \t0.00737156\t-0.190762\t-0.174049\t-0.158712\n",
      "99 \t10   \t0.00737156\t-0.190762\t-0.174049\t-0.158712\n",
      "Best individual is  Individual('d', [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]) -0.1587116145197014\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin     \tavg      \tmax      \n",
      "0  \t10   \t0.0331355\t-0.33517\t-0.291579\t-0.239407\n",
      "1  \t10   \t0.0265213\t-0.296064\t-0.25935 \t-0.202378\n",
      "2  \t10   \t0.0273627\t-0.29298 \t-0.246086\t-0.197711\n",
      "3  \t10   \t0.0267494\t-0.267823\t-0.228627\t-0.191722\n",
      "4  \t10   \t0.0243832\t-0.267823\t-0.222498\t-0.191722\n",
      "5  \t10   \t0.0244871\t-0.267823\t-0.219831\t-0.191722\n",
      "6  \t10   \t0.0218298\t-0.256047\t-0.215114\t-0.191722\n",
      "7  \t10   \t0.0213929\t-0.253678\t-0.214877\t-0.191722\n",
      "8  \t10   \t0.0204185\t-0.251524\t-0.214227\t-0.191722\n",
      "9  \t10   \t0.0133904\t-0.243073\t-0.206326\t-0.191722\n",
      "10 \t10   \t0.0130205\t-0.230172\t-0.202904\t-0.176879\n",
      "11 \t10   \t0.0132829\t-0.230172\t-0.20165 \t-0.176879\n",
      "12 \t10   \t0.00947118\t-0.211662\t-0.197843\t-0.176879\n",
      "13 \t10   \t0.00947118\t-0.211662\t-0.197843\t-0.176879\n",
      "14 \t10   \t0.00947118\t-0.211662\t-0.197843\t-0.176879\n",
      "15 \t10   \t0.0111471 \t-0.211662\t-0.196328\t-0.176879\n",
      "16 \t10   \t0.0128984 \t-0.211662\t-0.193026\t-0.171348\n",
      "17 \t10   \t0.0128984 \t-0.211662\t-0.193026\t-0.171348\n",
      "18 \t10   \t0.0128984 \t-0.211662\t-0.193026\t-0.171348\n",
      "19 \t10   \t0.0125207 \t-0.211662\t-0.191872\t-0.171348\n",
      "20 \t10   \t0.012447  \t-0.211192\t-0.191825\t-0.171348\n",
      "21 \t10   \t0.012447  \t-0.211192\t-0.191825\t-0.171348\n",
      "22 \t10   \t0.0125222 \t-0.211192\t-0.191465\t-0.171348\n",
      "23 \t10   \t0.0119269 \t-0.211192\t-0.189977\t-0.171348\n",
      "24 \t10   \t0.0119269 \t-0.211192\t-0.189977\t-0.171348\n",
      "25 \t10   \t0.0135709 \t-0.211192\t-0.188766\t-0.166003\n",
      "26 \t10   \t0.0135709 \t-0.211192\t-0.188766\t-0.166003\n",
      "27 \t10   \t0.0113395 \t-0.205299\t-0.186456\t-0.166003\n",
      "28 \t10   \t0.0120205 \t-0.205299\t-0.184933\t-0.166003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 \t10   \t0.0119837 \t-0.205299\t-0.18475 \t-0.166003\n",
      "30 \t10   \t0.0112212 \t-0.200486\t-0.184269\t-0.166003\n",
      "31 \t10   \t0.0112212 \t-0.200486\t-0.184269\t-0.166003\n",
      "32 \t10   \t0.0112212 \t-0.200486\t-0.184269\t-0.166003\n",
      "33 \t10   \t0.0112091 \t-0.200486\t-0.184258\t-0.166003\n",
      "34 \t10   \t0.0112091 \t-0.200486\t-0.184258\t-0.166003\n",
      "35 \t10   \t0.0111943 \t-0.200486\t-0.183898\t-0.166003\n",
      "36 \t10   \t0.0111943 \t-0.200486\t-0.183898\t-0.166003\n",
      "37 \t10   \t0.0111943 \t-0.200486\t-0.183898\t-0.166003\n",
      "38 \t10   \t0.0111943 \t-0.200486\t-0.183898\t-0.166003\n",
      "39 \t10   \t0.0111943 \t-0.200486\t-0.183898\t-0.166003\n",
      "40 \t10   \t0.0111943 \t-0.200486\t-0.183898\t-0.166003\n",
      "41 \t10   \t0.0111943 \t-0.200486\t-0.183898\t-0.166003\n",
      "42 \t10   \t0.0125383 \t-0.200486\t-0.180895\t-0.162071\n",
      "43 \t10   \t0.0119791 \t-0.200486\t-0.180426\t-0.162071\n",
      "44 \t10   \t0.0119791 \t-0.200486\t-0.180426\t-0.162071\n",
      "45 \t10   \t0.0119791 \t-0.200486\t-0.180426\t-0.162071\n",
      "46 \t10   \t0.0119791 \t-0.200486\t-0.180426\t-0.162071\n",
      "47 \t10   \t0.0119791 \t-0.200486\t-0.180426\t-0.162071\n",
      "48 \t10   \t0.0119791 \t-0.200486\t-0.180426\t-0.162071\n",
      "49 \t10   \t0.0119791 \t-0.200486\t-0.180426\t-0.162071\n",
      "50 \t10   \t0.0119791 \t-0.200486\t-0.180426\t-0.162071\n",
      "51 \t10   \t0.0127135 \t-0.200486\t-0.17998 \t-0.157617\n",
      "52 \t10   \t0.0127135 \t-0.200486\t-0.17998 \t-0.157617\n",
      "53 \t10   \t0.0127028 \t-0.200486\t-0.179926\t-0.157617\n",
      "54 \t10   \t0.0111223 \t-0.192915\t-0.176624\t-0.157617\n",
      "55 \t10   \t0.010507  \t-0.192915\t-0.176102\t-0.157617\n",
      "56 \t10   \t0.010507  \t-0.192915\t-0.176102\t-0.157617\n",
      "57 \t10   \t0.00975092\t-0.187238\t-0.173266\t-0.157617\n",
      "58 \t10   \t0.00975092\t-0.187238\t-0.173266\t-0.157617\n",
      "59 \t10   \t0.00975092\t-0.187238\t-0.173266\t-0.157617\n",
      "60 \t10   \t0.00975092\t-0.187238\t-0.173266\t-0.157617\n",
      "61 \t10   \t0.00975092\t-0.187238\t-0.173266\t-0.157617\n",
      "62 \t10   \t0.00955354\t-0.186502\t-0.172771\t-0.157617\n",
      "63 \t10   \t0.00955354\t-0.186502\t-0.172771\t-0.157617\n",
      "64 \t10   \t0.00955354\t-0.186502\t-0.172771\t-0.157617\n",
      "65 \t10   \t0.00955354\t-0.186502\t-0.172771\t-0.157617\n",
      "66 \t10   \t0.00955354\t-0.186502\t-0.172771\t-0.157617\n",
      "67 \t10   \t0.00955354\t-0.186502\t-0.172771\t-0.157617\n",
      "68 \t10   \t0.00955354\t-0.186502\t-0.172771\t-0.157617\n",
      "69 \t10   \t0.00955354\t-0.186502\t-0.172771\t-0.157617\n",
      "70 \t10   \t0.00962455\t-0.186502\t-0.172654\t-0.157617\n",
      "71 \t10   \t0.00962455\t-0.186502\t-0.172654\t-0.157617\n",
      "72 \t10   \t0.00962455\t-0.186502\t-0.172654\t-0.157617\n",
      "73 \t10   \t0.00897495\t-0.185405\t-0.172128\t-0.157617\n",
      "74 \t10   \t0.00897495\t-0.185405\t-0.172128\t-0.157617\n",
      "75 \t10   \t0.00897495\t-0.185405\t-0.172128\t-0.157617\n",
      "76 \t10   \t0.00897495\t-0.185405\t-0.172128\t-0.157617\n",
      "77 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "78 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "79 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "80 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "81 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "82 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "83 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "84 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "85 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "86 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "87 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "88 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "89 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "90 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "91 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "92 \t10   \t0.00935662\t-0.185405\t-0.171682\t-0.157617\n",
      "93 \t10   \t0.00852844\t-0.185405\t-0.170819\t-0.157617\n",
      "94 \t10   \t0.00852844\t-0.185405\t-0.170819\t-0.157617\n",
      "95 \t10   \t0.00852844\t-0.185405\t-0.170819\t-0.157617\n",
      "96 \t10   \t0.00823486\t-0.184348\t-0.169524\t-0.157617\n",
      "97 \t10   \t0.00823486\t-0.184348\t-0.169524\t-0.157617\n",
      "98 \t10   \t0.00823486\t-0.184348\t-0.169524\t-0.157617\n",
      "99 \t10   \t0.00823486\t-0.184348\t-0.169524\t-0.157617\n",
      "Best individual is  Individual('d', [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]) -0.15761698267900792\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin      \tavg      \tmax      \n",
      "0  \t10   \t0.0228301\t-0.328276\t-0.278807\t-0.249629\n",
      "1  \t10   \t0.0147936\t-0.301028\t-0.264142\t-0.246632\n",
      "2  \t10   \t0.0160129\t-0.273345\t-0.256959\t-0.222357\n",
      "3  \t10   \t0.0174659\t-0.270647\t-0.244104\t-0.221907\n",
      "4  \t10   \t0.019073 \t-0.270647\t-0.243004\t-0.211359\n",
      "5  \t10   \t0.0166411\t-0.265306\t-0.239368\t-0.211359\n",
      "6  \t10   \t0.015478 \t-0.259727\t-0.235565\t-0.211359\n",
      "7  \t10   \t0.0139589\t-0.258299\t-0.23198 \t-0.211359\n",
      "8  \t10   \t0.0158074\t-0.249844\t-0.226968\t-0.19452 \n",
      "9  \t10   \t0.0148352\t-0.249844\t-0.221531\t-0.19452 \n",
      "10 \t10   \t0.012784 \t-0.240803\t-0.220283\t-0.19452 \n",
      "11 \t10   \t0.0118043\t-0.240803\t-0.217423\t-0.19452 \n",
      "12 \t10   \t0.00978186\t-0.226494\t-0.211703\t-0.19452 \n",
      "13 \t10   \t0.0124291 \t-0.226494\t-0.209639\t-0.186108\n",
      "14 \t10   \t0.012764  \t-0.226494\t-0.208763\t-0.186108\n",
      "15 \t10   \t0.0189464 \t-0.226494\t-0.205418\t-0.161063\n",
      "16 \t10   \t0.0184538 \t-0.226494\t-0.20453 \t-0.161063\n",
      "17 \t10   \t0.0186134 \t-0.226494\t-0.204132\t-0.161063\n",
      "18 \t10   \t0.0195833 \t-0.226494\t-0.201485\t-0.161063\n",
      "19 \t10   \t0.0179444 \t-0.222924\t-0.199649\t-0.161063\n",
      "20 \t10   \t0.0168064 \t-0.222924\t-0.197507\t-0.161063\n",
      "21 \t10   \t0.0158856 \t-0.216202\t-0.196835\t-0.161063\n",
      "22 \t10   \t0.0158856 \t-0.216202\t-0.196835\t-0.161063\n",
      "23 \t10   \t0.0182304 \t-0.210907\t-0.192505\t-0.156455\n",
      "24 \t10   \t0.0182304 \t-0.210907\t-0.192505\t-0.156455\n",
      "25 \t10   \t0.017249  \t-0.20813 \t-0.190853\t-0.156455\n",
      "26 \t10   \t0.017249  \t-0.20813 \t-0.190853\t-0.156455\n",
      "27 \t10   \t0.0187349 \t-0.20813 \t-0.187427\t-0.156455\n",
      "28 \t10   \t0.0187349 \t-0.20813 \t-0.187427\t-0.156455\n",
      "29 \t10   \t0.0176203 \t-0.20813 \t-0.185725\t-0.156455\n",
      "30 \t10   \t0.0176203 \t-0.20813 \t-0.185725\t-0.156455\n",
      "31 \t10   \t0.0166578 \t-0.20813 \t-0.184198\t-0.156455\n",
      "32 \t10   \t0.0157336 \t-0.20089 \t-0.183474\t-0.156455\n",
      "33 \t10   \t0.0157336 \t-0.20089 \t-0.183474\t-0.156455\n",
      "34 \t10   \t0.0157336 \t-0.20089 \t-0.183474\t-0.156455\n",
      "35 \t10   \t0.0157336 \t-0.20089 \t-0.183474\t-0.156455\n",
      "36 \t10   \t0.0157336 \t-0.20089 \t-0.183474\t-0.156455\n",
      "37 \t10   \t0.0157336 \t-0.20089 \t-0.183474\t-0.156455\n",
      "38 \t10   \t0.0157336 \t-0.20089 \t-0.183474\t-0.156455\n",
      "39 \t10   \t0.0149479 \t-0.20089 \t-0.180877\t-0.156455\n",
      "40 \t10   \t0.0149479 \t-0.20089 \t-0.180877\t-0.156455\n",
      "41 \t10   \t0.0149479 \t-0.20089 \t-0.180877\t-0.156455\n",
      "42 \t10   \t0.0149479 \t-0.20089 \t-0.180877\t-0.156455\n",
      "43 \t10   \t0.0149479 \t-0.20089 \t-0.180877\t-0.156455\n",
      "44 \t10   \t0.0131794 \t-0.194745\t-0.178399\t-0.156455\n",
      "45 \t10   \t0.0122241 \t-0.194745\t-0.176969\t-0.156455\n",
      "46 \t10   \t0.0122241 \t-0.194745\t-0.176969\t-0.156455\n",
      "47 \t10   \t0.0122241 \t-0.194745\t-0.176969\t-0.156455\n",
      "48 \t10   \t0.0122241 \t-0.194745\t-0.176969\t-0.156455\n",
      "49 \t10   \t0.0122241 \t-0.194745\t-0.176969\t-0.156455\n",
      "50 \t10   \t0.0122241 \t-0.194745\t-0.176969\t-0.156455\n",
      "51 \t10   \t0.0115322 \t-0.194745\t-0.176036\t-0.156455\n",
      "52 \t10   \t0.010458  \t-0.186983\t-0.175259\t-0.156455\n",
      "53 \t10   \t0.010458  \t-0.186983\t-0.175259\t-0.156455\n",
      "54 \t10   \t0.010458  \t-0.186983\t-0.175259\t-0.156455\n",
      "55 \t10   \t0.010458  \t-0.186983\t-0.175259\t-0.156455\n",
      "56 \t10   \t0.010458  \t-0.186983\t-0.175259\t-0.156455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 \t10   \t0.0100853 \t-0.186108\t-0.174877\t-0.156455\n",
      "58 \t10   \t0.0105932 \t-0.186108\t-0.17298 \t-0.156455\n",
      "59 \t10   \t0.0105932 \t-0.186108\t-0.17298 \t-0.156455\n",
      "60 \t10   \t0.0101578 \t-0.186108\t-0.171167\t-0.156455\n",
      "61 \t10   \t0.0101578 \t-0.186108\t-0.171167\t-0.156455\n",
      "62 \t10   \t0.0101578 \t-0.186108\t-0.171167\t-0.156455\n",
      "63 \t10   \t0.0101578 \t-0.186108\t-0.171167\t-0.156455\n",
      "64 \t10   \t0.0101578 \t-0.186108\t-0.171167\t-0.156455\n",
      "65 \t10   \t0.0098128 \t-0.186108\t-0.170458\t-0.156455\n",
      "66 \t10   \t0.0098128 \t-0.186108\t-0.170458\t-0.156455\n",
      "67 \t10   \t0.0098128 \t-0.186108\t-0.170458\t-0.156455\n",
      "68 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "69 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "70 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "71 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "72 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "73 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "74 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "75 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "76 \t10   \t0.00954056\t-0.186108\t-0.168942\t-0.156455\n",
      "77 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "78 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "79 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "80 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "81 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "82 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "83 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "84 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "85 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "86 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "87 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "88 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "89 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "90 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "91 \t10   \t0.00873562\t-0.183155\t-0.16845 \t-0.156455\n",
      "92 \t10   \t0.00859937\t-0.183155\t-0.168354\t-0.156455\n",
      "93 \t10   \t0.00851122\t-0.183155\t-0.167849\t-0.156455\n",
      "94 \t10   \t0.00851122\t-0.183155\t-0.167849\t-0.156455\n",
      "95 \t10   \t0.00851122\t-0.183155\t-0.167849\t-0.156455\n",
      "96 \t10   \t0.00851122\t-0.183155\t-0.167849\t-0.156455\n",
      "97 \t10   \t0.00851122\t-0.183155\t-0.167849\t-0.156455\n",
      "98 \t10   \t0.00851122\t-0.183155\t-0.167849\t-0.156455\n",
      "99 \t10   \t0.0077652 \t-0.183155\t-0.16721 \t-0.156455\n",
      "Best individual is  Individual('d', [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]) -0.15645454272102333\n",
      "Original dataset shape Counter({-1: 1742, 1: 293})\n",
      "Resampled dataset shape Counter({-1: 1742, 1: 586})\n",
      "gen\tevals\tstd      \tmin      \tavg      \tmax      \n",
      "0  \t10   \t0.0366667\t-0.331961\t-0.273867\t-0.207311\n",
      "1  \t10   \t0.0286688\t-0.306906\t-0.265638\t-0.207311\n",
      "2  \t10   \t0.0219132\t-0.295203\t-0.254425\t-0.207311\n",
      "3  \t10   \t0.0156624\t-0.265931\t-0.245175\t-0.207311\n",
      "4  \t10   \t0.0169562\t-0.25643 \t-0.233279\t-0.200681\n",
      "5  \t10   \t0.0179801\t-0.25643 \t-0.229151\t-0.200681\n",
      "6  \t10   \t0.0205206\t-0.25643 \t-0.220487\t-0.186735\n",
      "7  \t10   \t0.0202569\t-0.25643 \t-0.219719\t-0.186735\n",
      "8  \t10   \t0.0174376\t-0.24594 \t-0.217837\t-0.186735\n",
      "9  \t10   \t0.0161925\t-0.24594 \t-0.216062\t-0.186735\n",
      "10 \t10   \t0.0167104\t-0.24594 \t-0.214652\t-0.184079\n",
      "11 \t10   \t0.0167104\t-0.24594 \t-0.214652\t-0.184079\n",
      "12 \t10   \t0.0151058\t-0.242009\t-0.212812\t-0.184079\n",
      "13 \t10   \t0.0121184\t-0.228938\t-0.208909\t-0.184079\n",
      "14 \t10   \t0.0125344\t-0.228938\t-0.207411\t-0.184079\n",
      "15 \t10   \t0.0129508\t-0.228938\t-0.205027\t-0.184079\n",
      "16 \t10   \t0.0124808\t-0.223191\t-0.200037\t-0.17892 \n",
      "17 \t10   \t0.0124808\t-0.223191\t-0.200037\t-0.17892 \n",
      "18 \t10   \t0.0103939\t-0.20916 \t-0.198611\t-0.17892 \n",
      "19 \t10   \t0.0103939\t-0.20916 \t-0.198611\t-0.17892 \n",
      "20 \t10   \t0.0100454\t-0.20916 \t-0.196974\t-0.17892 \n",
      "21 \t10   \t0.0100454\t-0.20916 \t-0.196974\t-0.17892 \n",
      "22 \t10   \t0.00906761\t-0.208783\t-0.194435\t-0.17892 \n",
      "23 \t10   \t0.00890874\t-0.208783\t-0.193745\t-0.17892 \n",
      "24 \t10   \t0.00890874\t-0.208783\t-0.193745\t-0.17892 \n",
      "25 \t10   \t0.00823038\t-0.206497\t-0.193299\t-0.17892 \n",
      "26 \t10   \t0.00823038\t-0.206497\t-0.193299\t-0.17892 \n",
      "27 \t10   \t0.00823038\t-0.206497\t-0.193299\t-0.17892 \n",
      "28 \t10   \t0.00823038\t-0.206497\t-0.193299\t-0.17892 \n",
      "29 \t10   \t0.00823038\t-0.206497\t-0.193299\t-0.17892 \n",
      "30 \t10   \t0.00791813\t-0.206497\t-0.193043\t-0.17892 \n",
      "31 \t10   \t0.00785284\t-0.20611 \t-0.193005\t-0.17892 \n",
      "32 \t10   \t0.0181074 \t-0.201768\t-0.187797\t-0.135688\n",
      "33 \t10   \t0.0178115 \t-0.200392\t-0.185137\t-0.135688\n",
      "34 \t10   \t0.017377  \t-0.200392\t-0.184132\t-0.135688\n",
      "35 \t10   \t0.017377  \t-0.200392\t-0.184132\t-0.135688\n",
      "36 \t10   \t0.017377  \t-0.200392\t-0.184132\t-0.135688\n",
      "37 \t10   \t0.0162946 \t-0.195323\t-0.181115\t-0.135688\n",
      "38 \t10   \t0.0162946 \t-0.195323\t-0.181115\t-0.135688\n",
      "39 \t10   \t0.0162946 \t-0.195323\t-0.181115\t-0.135688\n",
      "40 \t10   \t0.0194396 \t-0.195323\t-0.177586\t-0.135688\n",
      "41 \t10   \t0.0194396 \t-0.195323\t-0.177586\t-0.135688\n",
      "42 \t10   \t0.0194795 \t-0.195323\t-0.175366\t-0.135688\n",
      "43 \t10   \t0.0194795 \t-0.195323\t-0.175366\t-0.135688\n",
      "44 \t10   \t0.0194795 \t-0.195323\t-0.175366\t-0.135688\n",
      "45 \t10   \t0.0194795 \t-0.195323\t-0.175366\t-0.135688\n",
      "46 \t10   \t0.0194795 \t-0.195323\t-0.175366\t-0.135688\n",
      "47 \t10   \t0.0194795 \t-0.195323\t-0.175366\t-0.135688\n",
      "48 \t10   \t0.0193945 \t-0.195323\t-0.175232\t-0.135688\n",
      "49 \t10   \t0.0193945 \t-0.195323\t-0.175232\t-0.135688\n",
      "50 \t10   \t0.018759  \t-0.195323\t-0.174259\t-0.135688\n",
      "51 \t10   \t0.018759  \t-0.195323\t-0.174259\t-0.135688\n",
      "52 \t10   \t0.018759  \t-0.195323\t-0.174259\t-0.135688\n",
      "53 \t10   \t0.018759  \t-0.195323\t-0.174259\t-0.135688\n",
      "54 \t10   \t0.018759  \t-0.195323\t-0.174259\t-0.135688\n",
      "55 \t10   \t0.018759  \t-0.195323\t-0.174259\t-0.135688\n",
      "56 \t10   \t0.0199818 \t-0.195323\t-0.171303\t-0.135688\n",
      "57 \t10   \t0.0199818 \t-0.195323\t-0.171303\t-0.135688\n",
      "58 \t10   \t0.0185587 \t-0.192708\t-0.169371\t-0.135688\n",
      "59 \t10   \t0.0185587 \t-0.192708\t-0.169371\t-0.135688\n",
      "60 \t10   \t0.0185587 \t-0.192708\t-0.169371\t-0.135688\n",
      "61 \t10   \t0.0185587 \t-0.192708\t-0.169371\t-0.135688\n",
      "62 \t10   \t0.0185587 \t-0.192708\t-0.169371\t-0.135688\n",
      "63 \t10   \t0.0185587 \t-0.192708\t-0.169371\t-0.135688\n",
      "64 \t10   \t0.0187185 \t-0.192708\t-0.168371\t-0.135688\n",
      "65 \t10   \t0.0187185 \t-0.192708\t-0.168371\t-0.135688\n",
      "66 \t10   \t0.0187185 \t-0.192708\t-0.168371\t-0.135688\n",
      "67 \t10   \t0.0187185 \t-0.192708\t-0.168371\t-0.135688\n",
      "68 \t10   \t0.0187185 \t-0.192708\t-0.168371\t-0.135688\n",
      "69 \t10   \t0.0187185 \t-0.192708\t-0.168371\t-0.135688\n",
      "70 \t10   \t0.0187185 \t-0.192708\t-0.168371\t-0.135688\n",
      "71 \t10   \t0.0187185 \t-0.192708\t-0.168371\t-0.135688\n",
      "72 \t10   \t0.0179122 \t-0.186929\t-0.167675\t-0.135688\n",
      "73 \t10   \t0.0179122 \t-0.186929\t-0.167675\t-0.135688\n",
      "74 \t10   \t0.0179122 \t-0.186929\t-0.167675\t-0.135688\n",
      "75 \t10   \t0.0179122 \t-0.186929\t-0.167675\t-0.135688\n",
      "76 \t10   \t0.0179122 \t-0.186929\t-0.167675\t-0.135688\n",
      "77 \t10   \t0.0179122 \t-0.186929\t-0.167675\t-0.135688\n",
      "78 \t10   \t0.0167596 \t-0.185743\t-0.165905\t-0.135688\n",
      "79 \t10   \t0.0162082 \t-0.185743\t-0.165036\t-0.135688\n",
      "80 \t10   \t0.0162082 \t-0.185743\t-0.165036\t-0.135688\n",
      "81 \t10   \t0.0162082 \t-0.185743\t-0.165036\t-0.135688\n",
      "82 \t10   \t0.0162082 \t-0.185743\t-0.165036\t-0.135688\n",
      "83 \t10   \t0.0162082 \t-0.185743\t-0.165036\t-0.135688\n",
      "84 \t10   \t0.0162082 \t-0.185743\t-0.165036\t-0.135688\n",
      "85 \t10   \t0.0162082 \t-0.185743\t-0.165036\t-0.135688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 \t10   \t0.0154584 \t-0.185743\t-0.164142\t-0.135688\n",
      "87 \t10   \t0.0154584 \t-0.185743\t-0.164142\t-0.135688\n",
      "88 \t10   \t0.0154584 \t-0.185743\t-0.164142\t-0.135688\n",
      "89 \t10   \t0.0136892 \t-0.184079\t-0.161567\t-0.135688\n",
      "90 \t10   \t0.0136892 \t-0.184079\t-0.161567\t-0.135688\n",
      "91 \t10   \t0.0136892 \t-0.184079\t-0.161567\t-0.135688\n",
      "92 \t10   \t0.0134781 \t-0.184079\t-0.16042 \t-0.135688\n",
      "93 \t10   \t0.0134781 \t-0.184079\t-0.16042 \t-0.135688\n",
      "94 \t10   \t0.0134781 \t-0.184079\t-0.16042 \t-0.135688\n",
      "95 \t10   \t0.0134781 \t-0.184079\t-0.16042 \t-0.135688\n",
      "96 \t10   \t0.0134781 \t-0.184079\t-0.16042 \t-0.135688\n",
      "97 \t10   \t0.0134781 \t-0.184079\t-0.16042 \t-0.135688\n",
      "98 \t10   \t0.0134781 \t-0.184079\t-0.16042 \t-0.135688\n",
      "99 \t10   \t0.0137906 \t-0.184079\t-0.157601\t-0.135688\n",
      "Best individual is  Individual('d', [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]) -0.13568776020704343\n"
     ]
    }
   ],
   "source": [
    "NDIM_DE_SMOTE = minority_samples.shape[0]\n",
    "n_majority = new_majorityclass_training.shape[0]\n",
    "p = 0.2\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMax, clf=None)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_int\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_int, NDIM_DE_SMOTE)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"select\", tools.selRandom, k=3)\n",
    "\n",
    "toolbox.register(\"evaluate\", compute_fitness, p,\n",
    "                 X_US,y_US,maj_class,min_class,syn)\n",
    "\n",
    "T = 10\n",
    "clf_weights = []\n",
    "clfs = []\n",
    "for t in range(T):\n",
    "    #generate synthetic samples from minority class\n",
    "    syn = compute_synthetics(X_US,y_US,maj_class,min_class)\n",
    "    \n",
    "    #compute DE and obtain the best subset of synthetics to train with\n",
    "    selection_mask = DE_oversampling(0.6,0.5,10,100)\n",
    "    selected_syn = []\n",
    "    for i, value in enumerate(selection_mask):\n",
    "        if selection_mask[i]>0:\n",
    "            selected_syn.append(syn[i])\n",
    "    selected_syn = np.array(selected_syn)\n",
    "    Xtr = np.vstack((X_US,selected_syn))\n",
    "    ytr = np.hstack((y_US,np.full(selected_syn.shape[0],min_class)))\n",
    "    \n",
    "    clf = trainDT(Xtr,ytr)\n",
    "    \n",
    "    y_pred = clf.predict(X_US)\n",
    "    e = sum(weights*(y_pred!=y_US))\n",
    "    \n",
    "    w_clf = 0.5*math.log((1-e)/e)\n",
    "    \n",
    "    Z = 2*math.sqrt(e*(1-e))\n",
    "    weights = weights*np.exp(-w_clf*y_US*y_pred)/Z\n",
    "    weights /= sum(weights)\n",
    "    \n",
    "    clf_weights.append(w_clf)\n",
    "    clfs.append(clf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier()]\n",
      "[inf, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "print(clfs)\n",
    "print(clf_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DERS_BOOST_classification(x,clfs,clf_weights):\n",
    "    S = 0\n",
    "    for t in range(len(clfs)):\n",
    "        y = clfs[t].predict(x)\n",
    "        S += clf_weights[t]*y\n",
    "    if S>=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "clf = trainDT(X_US,y_US)\n",
    "\n",
    "y_pred = clf.predict(X_US)\n",
    "y_pred[-2:] = -1\n",
    "fails = (y_pred!=y_US)\n",
    "e = sum(weights*fails)\n",
    "w_clf = 0.5*math.log((1-e)/e)\n",
    "Z = 2*math.sqrt(e*(1-e))\n",
    "b = -(w_clf*y_US*y_pred)\n",
    "a = np.exp(b)\n",
    "w = weights*a/Z\n",
    "print(w)\n",
    "w /= sum(w)\n",
    "print(w)\n",
    "print(sum(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DERS_BOOST_classification(X_test[0].reshape(1,-1),clfs,clf_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947\n",
      "(1045,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for x in X_test:\n",
    "    y_pred.append(DERS_BOOST_classification(x.reshape(1,-1),clfs,clf_weights))\n",
    "\n",
    "print(sum(y_pred==y_test))\n",
    "print(y_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
