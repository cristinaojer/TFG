{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import fetch_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli = fetch_datasets()['ecoli']\n",
    "X, y = ecoli.data, ecoli.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of features of the dataset \n",
    "D = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain problem labels and identify majoritary and minoritary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_train)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 226 instances for the majoritary class\n",
      "There are 26 instanes for the minoritary class\n"
     ]
    }
   ],
   "source": [
    "if sum(y_train == classes[0]) > sum(y_train == classes[1]):\n",
    "    maj_class = classes[0]\n",
    "    min_class = classes[1]\n",
    "else:\n",
    "    maj_class = classes[1]\n",
    "    min_class = classes[0]\n",
    "    \n",
    "print(\"There are {} instances for the majoritary class\".format(sum(y_train == maj_class)))\n",
    "print(\"There are {} instanes for the minoritary class\".format(sum(y_train == min_class)))\n",
    "classes = [maj_class,min_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE-guided UNDERSAMPLING of the majority class instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import array\n",
    "\n",
    "from deap import base\n",
    "from deap import benchmarks\n",
    "from deap import creator\n",
    "from deap import tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate the initial random population from the training set\n",
    "def load_individuals(X,y,creator,n):\n",
    "    maj_samples = X[y == maj_class]\n",
    "    min_samples = X[y == min_class]\n",
    "    individuals = []\n",
    "    for i in range(n):\n",
    "        random_maj = maj_samples[random.randint(0,maj_samples.shape[0]-1)]\n",
    "        random_min = min_samples[random.randint(0,min_samples.shape[0]-1)]\n",
    "        individual = np.asarray(np.concatenate((random_maj,random_min)))\n",
    "        \n",
    "        individual = creator(individual)\n",
    "        individuals.append(individual)\n",
    "    return individuals\n",
    "\n",
    "# returns the euclidean distance between two points\n",
    "def euclidean(v1, v2):\n",
    "    return sum((p-q)**2 for p, q in zip(v1, v2)) ** .5\n",
    "\n",
    "#returns the sum of the distances from each sample in X_train to the closest center\n",
    "#we are interested in minimizing this sum of distances\n",
    "def evaluate(X,individual):\n",
    "    S = 0\n",
    "    for x in X:\n",
    "        dist = dist_to_closest_center(x,individual[:D],individual[D:])\n",
    "        S += dist\n",
    "        \n",
    "    return S,\n",
    "\n",
    "#computes the euclidean distance for both centers and returns the shortest one\n",
    "def dist_to_closest_center(x,maj_center,min_center):\n",
    "    dist_majcenter = euclidean(x,maj_center)\n",
    "    dist_mincenter = euclidean(x,min_center)\n",
    "    return min(dist_majcenter,dist_mincenter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDIM = D*2\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "#creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMin)\n",
    "#creator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "#toolbox.register(\"attr_float\", random.uniform, -3, 3)\n",
    "#toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, NDIM)\n",
    "#toolbox.register(\"individual\", selectRandomSamplesOneForEachClass, creator.Individual)\n",
    "toolbox.register(\"population\",load_individuals, X_train, y_train, creator.Individual)\n",
    "#toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"select\", tools.selRandom, k=3)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DE_clustering(CR,F,POP_SIZE,NGEN):\n",
    "    # Differential evolution parameters\n",
    "    #CR = 0.25\n",
    "    #F = 1  \n",
    "    #MU = 300\n",
    "    #NGEN = 200    \n",
    "    \n",
    "    pop = toolbox.population(n=POP_SIZE);\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
    "    \n",
    "    # Evaluate the individuals\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, pop)\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, evals=len(pop), **record)\n",
    "    print(logbook.stream)\n",
    "    \n",
    "    for g in range(1, NGEN):\n",
    "        for k, agent in enumerate(pop):\n",
    "            a,b,c = toolbox.select(pop)\n",
    "            y = toolbox.clone(agent)\n",
    "            index = random.randrange(NDIM)\n",
    "            for i, value in enumerate(agent):\n",
    "                if i == index or random.random() < CR:\n",
    "                    y[i] = a[i] + F*(b[i]-c[i])\n",
    "            y.fitness.values = toolbox.evaluate(y)\n",
    "            if y.fitness > agent.fitness:\n",
    "                pop[k] = y\n",
    "            #print(pop[k].fitness)\n",
    "        hof.update(pop)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=g, evals=len(pop), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "    print(\"Best individual is \", hof[0], hof[0].fitness.values[0])\n",
    "    return hof[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute H clustering processes and obtain one pair of cluster centers for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tevals\tstd    \tmin    \tavg    \tmax    \n",
      "0  \t10   \t14.2305\t84.8616\t103.432\t130.488\n",
      "1  \t10   \t11.9002\t84.8616\t100.653\t124.026\n",
      "2  \t10   \t5.34695\t84.8616\t93.2184\t103.859\n",
      "3  \t10   \t5.34992\t84.8616\t90.0787\t102.8  \n",
      "4  \t10   \t5.86783\t82.0749\t89.2429\t102.8  \n",
      "5  \t10   \t3.45564\t82.0749\t86.3168\t93.6698\n",
      "6  \t10   \t3.2273 \t79.9328\t84.2603\t91.205 \n",
      "7  \t10   \t2.5765 \t79.9328\t82.6895\t86.9416\n",
      "8  \t10   \t1.3077 \t79.9328\t81.2072\t84.0781\n",
      "9  \t10   \t0.939264\t78.8625\t80.4401\t82.0347\n",
      "Best individual is  Individual('d', [0.365, 0.44, 0.48, 0.5, 0.44458984375, 0.39, 0.44249999999999995, 0.7, 0.43624999999999997, 0.48, 0.5, 0.61390625, 0.76671875, 0.7571875000000001]) 78.86252999364422\n",
      "gen\tevals\tstd    \tmin    \tavg    \tmax    \n",
      "0  \t10   \t13.6306\t83.0069\t103.393\t128.114\n",
      "1  \t10   \t12.0884\t83.0069\t100.621\t119.172\n",
      "2  \t10   \t13.1914\t83.0069\t97.8883\t119.172\n",
      "3  \t10   \t11.4786\t82.0614\t93.6299\t115.456\n",
      "4  \t10   \t5.65597\t81.6611\t89.2123\t98.5367\n",
      "5  \t10   \t5.42001\t81.6611\t89.0356\t97.1949\n",
      "6  \t10   \t5.61736\t79.7951\t86.26  \t96.3955\n",
      "7  \t10   \t5.28752\t78.092 \t84.8291\t96.3955\n",
      "8  \t10   \t4.15291\t76.7492\t81.1286\t89.9531\n",
      "9  \t10   \t2.96493\t76.7492\t79.9454\t88.0004\n",
      "Best individual is  Individual('d', [0.4465625, 0.47624999999999995, 0.48, 0.5, 0.49375, 0.31062500000000004, 0.391875, 0.5712499999999998, 0.39625, 0.48, 0.5, 0.5925, 0.7665625, 0.7474999999999999]) 76.74924179474024\n",
      "gen\tevals\tstd   \tmin    \tavg    \tmax    \n",
      "0  \t10   \t17.523\t86.0559\t112.382\t143.015\n",
      "1  \t10   \t12.2691\t86.0559\t107.143\t128.713\n",
      "2  \t10   \t11.9171\t86.0559\t106.937\t126.651\n",
      "3  \t10   \t10.1625\t86.0559\t102.811\t118.773\n",
      "4  \t10   \t10.2998\t77.8335\t99.7553\t113.892\n",
      "5  \t10   \t9.78342\t77.8335\t96.2233\t113.892\n",
      "6  \t10   \t8.05406\t77.8335\t94.7056\t105.754\n",
      "7  \t10   \t6.04569\t77.8335\t91.0932\t96.7927\n",
      "8  \t10   \t5.74607\t77.8335\t88.485 \t95.8164\n",
      "9  \t10   \t5.06778\t77.8335\t86.6071\t92.9551\n",
      "Best individual is  Individual('d', [0.38749999999999996, 0.45999999999999996, 0.48, 0.5, 0.5025, 0.405, 0.4, 0.665, 0.475, 0.48, 0.5, 0.5049999999999999, 0.7050000000000001, 0.7525]) 77.83353260435577\n",
      "gen\tevals\tstd   \tmin    \tavg    \tmax    \n",
      "0  \t10   \t21.758\t83.6365\t113.051\t145.027\n",
      "1  \t10   \t21.0775\t83.6365\t112.09 \t145.027\n",
      "2  \t10   \t12.1669\t83.6365\t98.9838\t120.715\n",
      "3  \t10   \t10.2133\t83.6365\t95.9702\t119.772\n",
      "4  \t10   \t5.79698\t83.6365\t90.0357\t104.551\n",
      "5  \t10   \t4.84795\t82.414 \t88.1862\t97.6282\n",
      "6  \t10   \t4.29326\t82.414 \t87.0861\t97.6282\n",
      "7  \t10   \t2.35023\t82.3222\t84.8925\t88.7651\n",
      "8  \t10   \t2.49098\t81.4303\t84.2515\t88.7651\n",
      "9  \t10   \t2.56807\t79.6683\t82.7162\t87.8853\n",
      "Best individual is  Individual('d', [0.39175781249999997, 0.47906250000000006, 0.48, 0.5, 0.4637500000000001, 0.3697558593750001, 0.4253125, 0.7100000000000001, 0.36, 0.48, 0.5, 0.4899999999999999, 0.7930078125000001, 0.720390625]) 79.66828757930932\n",
      "gen\tevals\tstd    \tmin    \tavg    \tmax    \n",
      "0  \t10   \t9.98798\t88.0389\t105.332\t119.379\n",
      "1  \t10   \t9.55323\t88.0389\t102.893\t114.216\n",
      "2  \t10   \t9.02844\t88.0389\t100.161\t113.445\n",
      "3  \t10   \t7.60108\t88.0389\t97.3734\t109.713\n",
      "4  \t10   \t5.90623\t88.0389\t95.1072\t105.389\n",
      "5  \t10   \t5.92736\t80.5423\t91.3037\t102.492\n",
      "6  \t10   \t4.26036\t80.5423\t87.6939\t93.9382\n",
      "7  \t10   \t4.07954\t80.5423\t85.4607\t92.6967\n",
      "8  \t10   \t3.7543 \t80.5423\t84.7486\t92.6967\n",
      "9  \t10   \t2.57332\t79.1669\t83.305 \t86.9749\n",
      "Best individual is  Individual('d', [0.38442382812500003, 0.46, 0.48, 0.5, 0.5090625, 0.35124999999999995, 0.356171875, 0.702353515625, 0.37421874999999993, 0.48, 0.5, 0.49953125, 0.7521484375, 0.8031250000000001]) 79.16687186584525\n",
      "gen\tevals\tstd    \tmin    \tavg    \tmax   \n",
      "0  \t10   \t26.4593\t89.3116\t122.309\t157.92\n",
      "1  \t10   \t22.3887\t89.3116\t114.847\t146.601\n",
      "2  \t10   \t17.1723\t85.9072\t105.54 \t126.12 \n",
      "3  \t10   \t15.2754\t85.9072\t101.778\t126.12 \n",
      "4  \t10   \t11.3379\t85.9072\t96.9095\t123.352\n",
      "5  \t10   \t8.69974\t82.9409\t92.9004\t106.828\n",
      "6  \t10   \t5.27308\t82.9409\t88.7616\t102.285\n",
      "7  \t10   \t5.32283\t82.3576\t87.1006\t100.749\n",
      "8  \t10   \t2.96118\t82.3576\t85.2391\t91.4941\n",
      "9  \t10   \t1.50177\t82.3576\t83.9341\t87.5497\n",
      "Best individual is  Individual('d', [0.41125000000000006, 0.4525, 0.48, 0.5, 0.51375, 0.2875, 0.4275, 0.7396875, 0.35375, 0.48, 0.5, 0.57, 0.6825, 0.7512500000000001]) 82.3576395706229\n"
     ]
    }
   ],
   "source": [
    "H = 6\n",
    "clustering_centers = []\n",
    "for i in range(H):\n",
    "    clustering_centers.append(DE_clustering(0.6,0.5,10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take majority samples and compute for each of them their cluster stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifies sample x to the class which center is closer to\n",
    "def classify(x,centers):\n",
    "    dist_majcenter = euclidean(x,centers[:len(x)])\n",
    "    dist_mincenter = euclidean(x,centers[len(x):])\n",
    "    return np.argmin([dist_majcenter,dist_mincenter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8333333333333334, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8333333333333334, 1.0, 0.16666666666666666, 0.8333333333333334, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "majority_samples = X_train[y_train==maj_class]\n",
    "\n",
    "cluster_stabilities = []\n",
    "for sample in majority_samples:\n",
    "    \n",
    "    S = 0\n",
    "    for clustering in clustering_centers:\n",
    "        c = classes[classify(sample,clustering)]\n",
    "        if c==maj_class:\n",
    "            S += 1\n",
    "    cluster_stabilities.append(S/H)\n",
    "\n",
    "print(cluster_stabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples in the majority class with the clustering stability value Ci higher than a given threshold alpha are non-bounday samples.\n",
    "We take alpha as 80% of the total clustering times (H???????????)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 7)\n",
      "(171, 7)\n"
     ]
    }
   ],
   "source": [
    "#alpha = H*0.8 ????????????????????\n",
    "alpha = 0.8\n",
    "boundary_points = majority_samples[np.array(cluster_stabilities)<=alpha]\n",
    "non_boundary_points = majority_samples[np.array(cluster_stabilities)>alpha]\n",
    "\n",
    "print(boundary_points.shape)\n",
    "print(non_boundary_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly under-sample the non boundary points of the majority class, giving more importance to the data distribution information in the under-sample process. (RUS puro o ponderando los ejemplos en base a su Ci?????????)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUÉ PROPORCIÓN DE LOS NON-BOUNDARY SELECCIONAMOS??????????'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 7)\n"
     ]
    }
   ],
   "source": [
    "#RUS PURO\n",
    "RUSsize = int(non_boundary_points.shape[0]*0.4)\n",
    "indices = np.random.randint(non_boundary_points.shape[0], size=RUSsize)\n",
    "nbp_us = non_boundary_points[indices]\n",
    "print(nbp_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 7)\n"
     ]
    }
   ],
   "source": [
    "#RUS ponderado por el cluster stability de cada ejemplo\n",
    "C_non_boundary = np.array(cluster_stabilities)[np.array(cluster_stabilities)>alpha]\n",
    "indices = np.random.choice(np.arange(non_boundary_points.shape[0]),size=RUSsize,\n",
    "                           p = C_non_boundary/sum(C_non_boundary))\n",
    "nbp_us = non_boundary_points[indices]\n",
    "print(nbp_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 7)\n"
     ]
    }
   ],
   "source": [
    "new_majorityclass_training = np.vstack((boundary_points,nbp_us))\n",
    "print(new_majorityclass_training.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE-guided OVERSAMPLING of the minority class instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA-BOOST combined with DE-guided resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_samples = X_train[y_train==min_class]\n",
    "#prepare adaboost training set joining the undersampled majority class instances with the minority class instances\n",
    "X_US = np.vstack((new_majorityclass_training,minority_samples))\n",
    "y_US = np.hstack((np.full(new_majorityclass_training.shape[0],maj_class),\n",
    "                  np.full(minority_samples.shape[0],min_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.full(X_US.shape[0],1/X_US.shape[0])\n",
    "#print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "for t in range(T):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SMOTE to the original undersampled set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({-1: 123, 1: 26})\n",
      "Resampled dataset shape Counter({-1: 123, 1: 52})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % Counter(y_US))\n",
    "sm = SMOTE(sampling_strategy = {maj_class: new_majorityclass_training.shape[0],min_class: minority_samples.shape[0]*2},\n",
    "           random_state=42)\n",
    "X_after_SMOTE, y_after_SMOTE = sm.fit_resample(X_US, y_US)\n",
    "print('Resampled dataset shape %s' % Counter(y_after_SMOTE))\n",
    "synthetic_samples = X_after_SMOTE[y_after_SMOTE==min_class][minority_samples.shape[0]:]\n",
    "#print('Synthetic samples: ',synthetic_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0]\n",
      "15\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1]\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_syn = synthetic_samples[individual]\n",
    "Xtr = np.vstack((X_US,selected_syn))\n",
    "Xtr.shape\n",
    "ytr = np.hstack((y_US,np.full(selected_syn.shape[0],min_class)))\n",
    "print(ytr)\n",
    "print(sum(ytr==min_class))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DE to select the best synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 7)\n",
      "(104,)\n",
      "Accuracy: 0.9111111111111111\n",
      "Gmean: 0.8770580193070293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8770580193070293"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "Xtr, Xtst, ytr, ytst = train_test_split(X_US, y_US, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "weights = np.full(Xtr.shape[0],1/Xtr.shape[0])\n",
    "dt = trainDT(Xtr,ytr,weights)\n",
    "Gmean(dt,Xtst,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "def compute_fitness(n_majority, p, individual, X_before_SMOTE,y_before_SMOTE,min_class,original_minority_samples):\n",
    "    #synthetic_samples = X[y==min_class][original_minority_samples.shape[0]:]\n",
    "    selected_sin = synthetic_samples[individual]\n",
    "    Xtr = np.vstack((X_before_SMOTE,selected_sin))\n",
    "    ytr =\n",
    "    np.hstack((np.full(new_majorityclass_training.shape[0],maj_class),\n",
    "                  np.full(minority_samples.shape[0],min_class)))\n",
    "    dt = trainDT(Xtr,)\n",
    "    G = geometric_mean_score(y_true, y_pred)\n",
    "    n_minority = len(individual)+sum(individual)\n",
    "    f = G - abs(1-(n_minority/n_majority*p))\n",
    "    return f,\n",
    "\n",
    "def trainDT(X_train,y_train,w):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train,y_train,sample_weight=w)\n",
    "    return clf\n",
    "\n",
    "def Gmean(clf,X_test,y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    gmean = geometric_mean_score(y_test, y_pred)\n",
    "    print(\"Gmean:\",gmean)\n",
    "    return gmean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristina/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "NDIM_DE_SMOTE = minority_samples.shape[0]\n",
    "n_majority = new_majorityclass_training.shape[0]\n",
    "p = 0.2\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "#creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_int\", random.randint, 0, 1)\n",
    "#toolbox.register(\"individual\", tools.initCycle, creator.Individual, toolbox.attr_int, n=NDIM_DE_SMOTE)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_int, NDIM_DE_SMOTE)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"select\", tools.selRandom, k=3)\n",
    "\n",
    "toolbox.register(\"evaluate\", compute_fitness, n_majority, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DE_oversampling(CR,F_0,POP_SIZE,NGEN):\n",
    "    # Differential evolution parameters\n",
    "    #CR = 0.25\n",
    "    #F = 1  \n",
    "    #MU = 300\n",
    "    #NGEN = 200    \n",
    "    \n",
    "    pop = toolbox.population(n=POP_SIZE);\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
    "    print(pop)\n",
    "    # Evaluate the individuals\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, pop)\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, evals=len(pop), **record)\n",
    "    print(logbook.stream)\n",
    "    \n",
    "    for g in range(1, NGEN):\n",
    "        for k, agent in enumerate(pop):\n",
    "            a,b,c = toolbox.select(pop)\n",
    "            #we adopt a self-adaptative operator\n",
    "            l = math.exp(1-(NGEN/(NGEN+1-g)))\n",
    "            F = F_0*(2**l)\n",
    "            d = toolbox.clone(agent) #donor vector\n",
    "            sig_d = toolbox.clone(agent)\n",
    "            y = toolbox.clone(agent)\n",
    "            index = random.randrange(NDIM_DE_SMOTE)\n",
    "            for i, value in enumerate(agent):\n",
    "                d[i] = a[i] + F*(b[i]-c[i]) #donor vector\n",
    "                #the mutated donor is mapped to binary space by a sigmoid function with displacement\n",
    "                sig_d[i] = round(1/(1+math.exp(-(d[i]))))\n",
    "                if i == index or random.random() < CR:\n",
    "                    #y[i] = a[i] + F*(b[i]-c[i])\n",
    "                    y[i] = sig_d[i]\n",
    "            y.fitness.values = toolbox.evaluate(y)\n",
    "            if y.fitness > agent.fitness:\n",
    "                pop[k] = y\n",
    "            #print(pop[k].fitness)\n",
    "        hof.update(pop)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=g, evals=len(pop), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "    print(\"Best individual is \", hof[0], hof[0].fitness.values[0])\n",
    "    return hof[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Individual('d', [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]), Individual('d', [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]), Individual('d', [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]), Individual('d', [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]), Individual('d', [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]), Individual('d', [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]), Individual('d', [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]), Individual('d', [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]), Individual('d', [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]), Individual('d', [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0])]\n",
      "gen\tevals\tstd       \tmin    \tavg    \tmax    \n",
      "0  \t10   \t0.00442623\t9.05902\t9.06377\t9.07541\n",
      "1  \t10   \t0.00386552\t9.06066\t9.06525\t9.07541\n",
      "2  \t10   \t0.00447454\t9.06393\t9.06967\t9.07541\n",
      "3  \t10   \t0.00486584\t9.06557\t9.07328\t9.08033\n",
      "4  \t10   \t0.00463677\t9.06557\t9.07541\t9.08033\n",
      "5  \t10   \t0.00334362\t9.06885\t9.07738\t9.08033\n",
      "6  \t10   \t0.00164752\t9.07705\t9.07984\t9.08197\n",
      "7  \t10   \t0.00131148\t9.07869\t9.08098\t9.08197\n",
      "8  \t10   \t0.000751242\t9.08033\t9.08148\t9.08197\n",
      "9  \t10   \t0.000655738\t9.08033\t9.08164\t9.08197\n",
      "10 \t10   \t0.000655738\t9.08033\t9.08164\t9.08197\n",
      "11 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "12 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "13 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "14 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "15 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "16 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "17 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "18 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "19 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "20 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "21 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "22 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "23 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "24 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "25 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "26 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "27 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "28 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "29 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "30 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "31 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "32 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "33 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "34 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "35 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "36 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "37 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "38 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "39 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "40 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "41 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "42 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "43 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "44 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "45 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "46 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "47 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "48 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "49 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "50 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "51 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "52 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "53 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "54 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "55 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "56 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "57 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "58 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "59 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "60 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "61 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "62 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "63 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "64 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "65 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "66 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "67 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "68 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "69 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "70 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "71 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "72 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "73 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "74 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "75 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "76 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "77 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "78 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "79 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "80 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "81 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "82 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "83 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "84 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "85 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "86 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "87 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "88 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "89 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "90 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "91 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "92 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "93 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "94 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "95 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "96 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "97 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "98 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "99 \t10   \t0          \t9.08197\t9.08197\t9.08197\n",
      "Best individual is  Individual('d', [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]) 9.081967213114755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Individual('d', [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DE_oversampling(0.6,0.5,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
